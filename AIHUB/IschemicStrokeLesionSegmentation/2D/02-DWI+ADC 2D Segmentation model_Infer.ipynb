{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import PIL.Image as Image\n",
    "\n",
    "import nibabel as nib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "from util.util import *\n",
    "from util.visualize import *\n",
    "from data.dataset_2d import *\n",
    "\n",
    "common_dir = '/home/ncp/workspace/202002n050/050.신경계 질환 관련 임상 및 진료 데이터'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "FILE_EXTENSION = ['.png', '.PNG', '.jpg', '.JPG', '.dcm', '.DCM', '.raw', '.RAW', '.svs', '.SVS']\n",
    "IMG_EXTENSION = ['.png', '.PNG', '.jpg', '.JPG', '.jpeg', '.JPEG']\n",
    "DCM_EXTENSION = ['.dcm', '.DCM']\n",
    "RAW_EXTENSION = ['.raw', '.RAW']\n",
    "NIFTI_EXTENSION = ['.nii']\n",
    "NP_EXTENSION = ['.npy']\n",
    "\n",
    "mask_common_dir = '/home/ncp/workspace/202002n050/050.신경계 질환 관련 임상 및 진료 데이터'\n",
    "\n",
    "\n",
    "def check_extension(filename, extension_ls=FILE_EXTENSION):\n",
    "    return any(filename.endswith(extension) for extension in extension_ls)\n",
    "\n",
    "\n",
    "def load_file_path(folder_path, extension_ls=FILE_EXTENSION, all_sub_folders=False):\n",
    "    \"\"\"find 'IMG_EXTENSION' file paths in folder.\n",
    "    \n",
    "    Parameters:\n",
    "        folder_path (str) -- folder directory\n",
    "        extension_ls (list) -- list of extensions\n",
    "    \n",
    "    Return:\n",
    "        file_paths (list) -- list of 'extension_ls' file paths\n",
    "    \"\"\"\n",
    "    \n",
    "    file_paths = []\n",
    "    assert os.path.isdir(folder_path), f'{folder_path} is not a valid directory'\n",
    "\n",
    "    for root, _, fnames in sorted(os.walk(folder_path)):\n",
    "        for fname in fnames:\n",
    "            if check_extension(fname, extension_ls):\n",
    "                path = os.path.join(root, fname)\n",
    "                file_paths.append(path)\n",
    "        if not all_sub_folders:\n",
    "            break\n",
    "\n",
    "    return file_paths[:]\n",
    "\n",
    "\n",
    "def gen_new_dir(new_dir):\n",
    "    try: \n",
    "        if not os.path.exists(new_dir): \n",
    "            os.makedirs(new_dir) \n",
    "            #print(f\"New directory!: {new_dir}\")\n",
    "    except OSError: \n",
    "        print(\"Error: Failed to create the directory.\")\n",
    "\n",
    "\n",
    "def find_dwi_adc_dir(img_folder_dir, fname):\n",
    "    dwi_folder_dir = os.path.join(img_folder_dir, fname, 'dwi')\n",
    "    adc_folder_dir = os.path.join(img_folder_dir, fname, 'adc')\n",
    "    if (os.path.isdir(dwi_folder_dir)) & (os.path.isdir(adc_folder_dir)):\n",
    "        return dwi_folder_dir, adc_folder_dir\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def find_mask_dir(mask_folder_dir, fname):\n",
    "    mask_folder_dir = os.path.join(mask_folder_dir, fname)\n",
    "    if (os.path.isdir(mask_folder_dir)):\n",
    "        return mask_folder_dir\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def pair_aihub_dwi_adc_img_mask_path(img_folder_dir, mask_folder_dir):\n",
    "    img_mask_path_dict = {}\n",
    "    for fname in sorted(os.listdir(img_folder_dir)):\n",
    "        dwi_adc_dir = find_dwi_adc_dir(img_folder_dir, fname)\n",
    "        mask_dir = find_mask_dir(mask_folder_dir, fname)\n",
    "        if dwi_adc_dir:\n",
    "            if mask_dir:\n",
    "                dwi_folder_dir, adc_folder_dir = dwi_adc_dir\n",
    "                dwi_path_ls = sorted(load_file_path(dwi_folder_dir, IMG_EXTENSION))\n",
    "                adc_path_ls = sorted(load_file_path(adc_folder_dir, IMG_EXTENSION))\n",
    "                img_path_ls = list(zip(dwi_path_ls,adc_path_ls))\n",
    "                mask_path_ls = sorted(load_file_path(mask_dir, IMG_EXTENSION))\n",
    "                img_mask_path_dict[fname] = [img_path_ls, mask_path_ls]\n",
    "    return img_mask_path_dict\n",
    "\n",
    "\n",
    "def select_train_val_test(img_mask_path_dict, fname_list):\n",
    "    tmp_dict = {}\n",
    "    for fname in fname_list:\n",
    "        if img_mask_path_dict.get(fname):\n",
    "            tmp_dict[fname] = img_mask_path_dict.get(fname)\n",
    "            \n",
    "    return tmp_dict\n",
    "\n",
    "\n",
    "def find_aihub_img_mask_paths(img_folder_dir, mask_folder_dir, fname_list):\n",
    "    img_mask_path_dict = pair_aihub_dwi_adc_img_mask_path(img_folder_dir, mask_folder_dir)\n",
    "    \n",
    "    img_mask_path_dict_sel = select_train_val_test(img_mask_path_dict, fname_list)\n",
    "    \n",
    "    img_path_arr = np.concatenate([[*img_path_ls] for img_path_ls, _ in img_mask_path_dict_sel.values()])\n",
    "    mask_path_arr = np.concatenate([mask_path_ls for _, mask_path_ls in img_mask_path_dict_sel.values()])\n",
    "    return img_path_arr, mask_path_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dwi_adc_loader(dwi_adc_path):\n",
    "    dwi_path, adc_path = dwi_adc_path\n",
    "    dwi_img = np.array(Image.open(dwi_path))\n",
    "    adc_img = np.array(Image.open(adc_path))\n",
    "    return np.stack([dwi_img,adc_img], axis=-1)\n",
    "def mask_loader(mask_path):\n",
    "    return np.expand_dims(np.where(np.array(Image.open(mask_path)),1,0), axis=-1).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets, models, transforms\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "\n",
    "def get_training_augmentation(params=None):\n",
    "    transform_list = []\n",
    "    \n",
    "    #transform_list.append(A.HorizontalFlip(p=.5))\n",
    "    #transform_list.append(A.VerticalFlip(p=.5))\n",
    "    #transform_list.append(A.ShiftScaleRotate(scale_limit=0.1, rotate_limit=5, shift_limit=0.2, border_mode=0, p=.5))\n",
    "    #transform_list.append(A.ShiftScaleRotate(scale_limit=0.01, rotate_limit=5, shift_limit=0., border_mode=0, p=.5))\n",
    "    \n",
    "    return A.Compose(transform_list)\n",
    "\n",
    "\n",
    "def get_preprocessing(params=None,resize=(256,256),convert=True):\n",
    "    transform_list = []\n",
    "    transform_list.append(A.Resize(*resize))\n",
    "    if convert:\n",
    "        transform_list.append(A.Normalize(mean=(0.5,0.5),  std=(0.5,0.5)))\n",
    "        #transform_list.append(A.Normalize(mean=(0.485, 0.456, 0.406),  std=(0.229, 0.224, 0.225)))\n",
    "        transform_list.append(ToTensorV2(transpose_mask=True))\n",
    "    return A.Compose(transform_list)\n",
    "\n",
    "\n",
    "class AIHUB_DWI_ADC_LesionSegDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, \n",
    "                 img_folder_dir, \n",
    "                 mask_folder_dir, \n",
    "                 data_df_path,\n",
    "                 img_loader=dwi_adc_loader, \n",
    "                 mask_loader=mask_loader,\n",
    "                 augmentation=None, \n",
    "                 preprocessing=None,\n",
    "                 mode='train'\n",
    "    ):\n",
    "        self.data_df = pd.read_csv(data_df_path)\n",
    "        self.img_loader = img_loader\n",
    "        self.mask_loader = mask_loader\n",
    "        self.augmentation = augmentation\n",
    "        self.preprocessing = preprocessing\n",
    "        self.mode = mode\n",
    "        self.fname_list = self.data_df[self.data_df[\"split_811\"] == self.mode].name.values\n",
    "        \n",
    "        self.img_path_arr, self.mask_path_arr = find_aihub_img_mask_paths(img_folder_dir, mask_folder_dir, self.fname_list)\n",
    "        if self.mode != 'train':\n",
    "            self.augmentation = None\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        image = self.img_loader(self.img_path_arr[index])\n",
    "        mask = self.mask_loader(self.mask_path_arr[index])\n",
    "        if self.augmentation:\n",
    "            sample = self.augmentation(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "        if self.preprocessing:\n",
    "            sample = self.preprocessing(image=image, mask=mask)\n",
    "            image, mask = sample['image'], sample['mask']\n",
    "        \n",
    "        return image, mask\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_path_arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image as Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            #self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            #self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = AIHUB_DWI_ADC_LesionSegDataset(\n",
    "    img_folder_dir = '/home/ncp/workspace/blocks1/dicom_to_png_2d/', \n",
    "    mask_folder_dir = '/home/ncp/workspace/blocks/refined_mask', \n",
    "    data_df_path = '/home/ncp/workspace/blocks1/aihub_df.csv',  \n",
    "    augmentation=None, \n",
    "    preprocessing=get_preprocessing(resize=(256,256)),\n",
    "    mode='test'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_val_dataset = AIHUB_DWI_ADC_LesionSegDataset(\n",
    "    img_folder_dir = '/home/ncp/workspace/blocks1/dicom_to_png_2d/', \n",
    "    mask_folder_dir = '/home/ncp/workspace/blocks/refined_mask', \n",
    "    data_df_path = '/home/ncp/workspace/blocks1/aihub_df.csv',  \n",
    "    augmentation=None, \n",
    "    preprocessing=get_preprocessing(resize=(256,256),convert=False),\n",
    "    mode='test'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best saved checkpoint\n",
    "save_path = \"./DWI_ADC_ckpt/2d_ckpt/Unet_resnet152\"\n",
    "best_model = torch.load(os.path.join(save_path, 'best_model01.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model on test set\n",
    "test_epoch = smp.utils.train.ValidEpoch(\n",
    "    model=best_model,\n",
    "    loss=loss,\n",
    "    metrics=metrics,\n",
    "    device=DEVICE,\n",
    ")\n",
    "\n",
    "logs = test_epoch.run(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_history = pd.read_csv(os.path.join(save_path,'results01.csv'))\n",
    "fig,ax = plt.subplots(1,2)\n",
    "\n",
    "ax[0].set_title('loss')\n",
    "ax[0].plot(np.array(train_history['train_loss']), 'b')\n",
    "ax[0].plot(np.array(train_history['valid_loss']), 'r')\n",
    "\n",
    "ax[1].set_title('acc')\n",
    "ax[1].plot(np.array(train_history['train_score']), 'b')\n",
    "ax[1].plot(np.array(train_history['valid_score']), 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_arr_to_png(im_2d, save_point, filename):\n",
    "    Image.fromarray(im_2d).save(os.path.join(save_point, filename+'.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best saved checkpoint\n",
    "save_path = \"./DWI_ADC_ckpt/2d_ckpt/Unet_resnet152\"\n",
    "best_model = torch.load(os.path.join(save_path, 'best_model01.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = AIHUB_DWI_ADC_LesionSegDataset(\n",
    "    img_folder_dir = '/home/ncp/workspace/blocks1/dicom_to_png_2d/', \n",
    "    mask_folder_dir = '/home/ncp/workspace/blocks/refined_mask', \n",
    "    data_df_path = '/home/ncp/workspace/blocks1/aihub_df.csv',  \n",
    "    augmentation=None, \n",
    "    preprocessing=get_preprocessing(resize=(256,256)),\n",
    "    mode='test',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_masks = []\n",
    "\n",
    "for data in tqdm(val_loader):\n",
    "    images, labels = data\n",
    "    images = images.to(DEVICE)\n",
    "    masks = labels.to(DEVICE)\n",
    "    pr_mask = best_model.predict(images)\n",
    "    predict_masks.append(pr_mask.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_masks = np.squeeze(np.vstack(predict_masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_masks_norm = (predict_masks*255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '/home/ncp/workspace/blocks1/dicom_to_png_2d/'\n",
    "len_cnt = 0\n",
    "tot_lesion_exist_dict = {}\n",
    "for fname in tqdm(val_dataset.fname_list):\n",
    "    z = len([p for p, _ in val_dataset.img_path_arr if fname in p])\n",
    "    tmp = predict_masks_norm[len_cnt:len_cnt+z]\n",
    "    save_point = os.path.join(save_dir, fname, 'pred_masks')\n",
    "    gen_new_dir(save_point)\n",
    "    for i, slice_img in enumerate(tmp):\n",
    "        save_name = str(i).zfill(3)\n",
    "        save_arr_to_png(slice_img, save_point, save_name)\n",
    "    len_cnt += z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = AIHUB_DWI_ADC_LesionSegDataset(\n",
    "    img_folder_dir = '/home/ncp/workspace/blocks1/dicom_to_png_2d/', \n",
    "    mask_folder_dir = '/home/ncp/workspace/blocks/refined_mask', \n",
    "    data_df_path = '/home/ncp/workspace/blocks1/aihub_df.csv',  \n",
    "    augmentation=None, \n",
    "    preprocessing=get_preprocessing(resize=(256,256)),\n",
    "    mode='val'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_masks = []\n",
    "\n",
    "for data in tqdm(val_loader):\n",
    "    images, labels = data\n",
    "    images = images.to(DEVICE)\n",
    "    masks = labels.to(DEVICE)\n",
    "    pr_mask = best_model.predict(images)\n",
    "    predict_masks.append(pr_mask.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_masks = np.squeeze(np.vstack(predict_masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_masks_norm = (predict_masks*255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '/home/ncp/workspace/blocks1/dicom_to_png_2d/'\n",
    "len_cnt = 0\n",
    "tot_lesion_exist_dict = {}\n",
    "for fname in tqdm(val_dataset.fname_list):\n",
    "    z = len([p for p, _ in val_dataset.img_path_arr if fname in p])\n",
    "    tmp = predict_masks_norm[len_cnt:len_cnt+z]\n",
    "    save_point = os.path.join(save_dir, fname, 'pred_masks')\n",
    "    gen_new_dir(save_point)\n",
    "    for i, slice_img in enumerate(tmp):\n",
    "        save_name = str(i).zfill(3)\n",
    "        save_arr_to_png(slice_img, save_point, save_name)\n",
    "    len_cnt += z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = AIHUB_DWI_ADC_LesionSegDataset(\n",
    "    img_folder_dir = '/home/ncp/workspace/blocks1/dicom_to_png_2d/', \n",
    "    mask_folder_dir = '/home/ncp/workspace/blocks/refined_mask', \n",
    "    data_df_path = '/home/ncp/workspace/blocks1/aihub_df.csv',  \n",
    "    augmentation=None, \n",
    "    preprocessing=get_preprocessing(resize=(256,256)),\n",
    "    mode='train'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_masks = []\n",
    "\n",
    "for data in tqdm(val_loader):\n",
    "    images, labels = data\n",
    "    images = images.to(DEVICE)\n",
    "    masks = labels.to(DEVICE)\n",
    "    pr_mask = best_model.predict(images)\n",
    "    predict_masks.append(pr_mask.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_masks = np.squeeze(np.vstack(predict_masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_masks_norm = (predict_masks*255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '/home/ncp/workspace/blocks1/dicom_to_png_2d/'\n",
    "len_cnt = 0\n",
    "tot_lesion_exist_dict = {}\n",
    "for fname in tqdm(val_dataset.fname_list):\n",
    "    z = len([p for p, _ in val_dataset.img_path_arr if fname in p])\n",
    "    tmp = predict_masks_norm[len_cnt:len_cnt+z]\n",
    "    save_point = os.path.join(save_dir, fname, 'pred_masks')\n",
    "    gen_new_dir(save_point)\n",
    "    for i, slice_img in enumerate(tmp):\n",
    "        save_name = str(i).zfill(3)\n",
    "        save_arr_to_png(slice_img, save_point, save_name)\n",
    "    len_cnt += z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################### 3d pred mask #####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE='cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = AIHUB_DWI_ADC_LesionSegDataset(\n",
    "    img_folder_dir = '/home/ncp/workspace/blocks2/dicom_to_png_2d_resample', \n",
    "    mask_folder_dir = '/home/ncp/workspace/blocks2/refined_mask_resample_2d', \n",
    "    data_df_path = '/home/ncp/workspace/blocks1/aihub_df.csv',  \n",
    "    augmentation=None, \n",
    "    preprocessing=get_preprocessing(resize=(256,256)),\n",
    "    mode='test'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_masks = []\n",
    "\n",
    "for data in tqdm(val_loader):\n",
    "    images, labels = data\n",
    "    images = images.to(DEVICE)\n",
    "    masks = labels.to(DEVICE)\n",
    "    pr_mask = best_model.predict(images)\n",
    "    predict_masks.append(pr_mask.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_masks = np.squeeze(np.vstack(predict_masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_masks.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save_dir = '/home/ncp/workspace/blocks1/pred_mask_resample'\n",
    "gen_new_dir(save_dir)\n",
    "len_cnt = 0\n",
    "tot_lesion_exist_dict = {}\n",
    "for fname in tqdm(val_dataset.fname_list):\n",
    "    z = len([p for p, _ in val_dataset.img_path_arr if fname in p])\n",
    "    tmp = predict_masks[len_cnt:len_cnt+z]\n",
    "    np.save(os.path.join(save_dir, fname+'.npy'), tmp)\n",
    "    len_cnt += z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = AIHUB_DWI_ADC_LesionSegDataset(\n",
    "    img_folder_dir = '/home/ncp/workspace/blocks2/dicom_to_png_2d_resample', \n",
    "    mask_folder_dir = '/home/ncp/workspace/blocks2/refined_mask_resample_2d', \n",
    "    data_df_path = '/home/ncp/workspace/blocks1/aihub_df.csv',  \n",
    "    augmentation=None, \n",
    "    preprocessing=get_preprocessing(resize=(256,256)),\n",
    "    mode='val'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_masks = []\n",
    "\n",
    "for data in tqdm(val_loader):\n",
    "    images, labels = data\n",
    "    images = images.to(DEVICE)\n",
    "    masks = labels.to(DEVICE)\n",
    "    pr_mask = best_model.predict(images)\n",
    "    predict_masks.append(pr_mask.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_masks = np.squeeze(np.vstack(predict_masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_masks.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '/home/ncp/workspace/blocks1/pred_mask_resample'\n",
    "gen_new_dir(save_dir)\n",
    "len_cnt = 0\n",
    "tot_lesion_exist_dict = {}\n",
    "for fname in tqdm(val_dataset.fname_list):\n",
    "    z = len([p for p, _ in val_dataset.img_path_arr if fname in p])\n",
    "    tmp = predict_masks[len_cnt:len_cnt+z]\n",
    "    np.save(os.path.join(save_dir, fname+'.npy'), tmp)\n",
    "    len_cnt += z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = AIHUB_DWI_ADC_LesionSegDataset(\n",
    "    img_folder_dir = '/home/ncp/workspace/blocks2/dicom_to_png_2d_resample', \n",
    "    mask_folder_dir = '/home/ncp/workspace/blocks2/refined_mask_resample_2d', \n",
    "    data_df_path = '/home/ncp/workspace/blocks1/aihub_df.csv',  \n",
    "    augmentation=None, \n",
    "    preprocessing=get_preprocessing(resize=(256,256)),\n",
    "    mode='train'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_masks = []\n",
    "\n",
    "for data in tqdm(val_loader):\n",
    "    images, labels = data\n",
    "    images = images.to(DEVICE)\n",
    "    masks = labels.to(DEVICE)\n",
    "    pr_mask = best_model.predict(images)\n",
    "    predict_masks.append(pr_mask.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_masks = np.squeeze(np.vstack(predict_masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_masks.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '/home/ncp/workspace/blocks1/pred_mask_resample'\n",
    "gen_new_dir(save_dir)\n",
    "len_cnt = 0\n",
    "tot_lesion_exist_dict = {}\n",
    "for fname in tqdm(val_dataset.fname_list):\n",
    "    z = len([p for p, _ in val_dataset.img_path_arr if fname in p])\n",
    "    tmp = predict_masks[len_cnt:len_cnt+z]\n",
    "    np.save(os.path.join(save_dir, fname+'.npy'), tmp)\n",
    "    len_cnt += z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#red:FalsePositive / green:TruePositive / blue:FalseNegative\n",
    "for i in range(1950, 1960):\n",
    "    image, mask = vis_val_dataset[i] \n",
    "    predict= predict_masks[i]\n",
    "    image_rgb = visualize_grayscale(np.squeeze(image[:,:,0]))\n",
    "    predict= predict.astype(np.uint8)\n",
    "    predict= predict[:,:,np.newaxis]\n",
    "    intersect_mask = mask*predict\n",
    "    only_mask = np.where((mask-intersect_mask)==1, 1, 0)\n",
    "    only_pred = np.where((predict-intersect_mask)==1, 1, 0)\n",
    "    tp_np_mask = np.concatenate([only_pred,intersect_mask,only_mask], axis=-1)*255\n",
    "    vis = image_rgb/2 + tp_np_mask/2\n",
    "    vis = vis.astype(np.uint8)\n",
    "    visualize(image=image_rgb, result=tp_np_mask, visualize=vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code reference: https://gist.github.com/gergf/acd8e3fd23347cb9e6dc572f00c63d79\n",
    "def dice(true_mask, pred_mask, non_seg_score=0.0):\n",
    "    \"\"\"\n",
    "        Computes the Dice coefficient.\n",
    "        Args:\n",
    "            true_mask : Array of arbitrary shape.\n",
    "            pred_mask : Array with the same shape than true_mask.  \n",
    "        \n",
    "        Returns:\n",
    "            A scalar representing the Dice coefficient between the two segmentations. \n",
    "        \n",
    "    \"\"\"\n",
    "    assert true_mask.shape == pred_mask.shape\n",
    "\n",
    "    true_mask = np.asarray(true_mask).astype(np.bool_)\n",
    "    pred_mask = np.asarray(pred_mask).astype(np.bool_)\n",
    "\n",
    "    # If both segmentations are all zero, the dice will be 1. (Developer decision)\n",
    "    im_sum = true_mask.sum() + pred_mask.sum()\n",
    "    if im_sum == 0:\n",
    "        return non_seg_score\n",
    "\n",
    "    # Compute Dice coefficient\n",
    "    intersection = np.logical_and(true_mask, pred_mask)\n",
    "    return 2. * intersection.sum() / im_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_avg = 0\n",
    "cnt = 0\n",
    "for i in range(len(vis_val_dataset)):\n",
    "    image, mask = vis_val_dataset[i] \n",
    "    if (predict_masks[i].max() != 0.) & (mask.max() != 0.):\n",
    "        dice_avg += dice(np.squeeze(mask.astype(np.uint8)), predict_masks[i].astype(np.uint8))\n",
    "        cnt += 1\n",
    "    else:\n",
    "        pass\n",
    "dice_avg /= cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_score_list = []\n",
    "cnt = 0\n",
    "for i in range(len(vis_val_dataset)):\n",
    "    image, mask = vis_val_dataset[i] \n",
    "    if (predict_masks[i].max() != 0.) & (mask.max() != 0.):\n",
    "        dice_score_list.append([i,dice(np.squeeze(mask.astype(np.uint8)), predict_masks[i].astype(np.uint8))])\n",
    "        cnt += 1\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_score_arr = np.array(dice_score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset_idx = dice_score_arr[:,0]\n",
    "val_dataset_dice = dice_score_arr[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_idx = int(val_dataset_idx[np.argmin(val_dataset_dice)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset_dice_w_idx = [[dice, i] for i, dice in enumerate(val_dataset_dice)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset_dice_w_idx = sorted(val_dataset_dice_w_idx, key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset_dice_w_idx[1100][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset_dice_w_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.min(val_dataset_dice))\n",
    "#red:FalsePositive / green:TruePositive / blue:FalseNegative\n",
    "for N in range(600,1200):\n",
    "    i = val_dataset_dice_w_idx[N][1]\n",
    "    print(i)\n",
    "    image, mask = vis_val_dataset[i] \n",
    "    predict= predict_masks[i]\n",
    "    image_rgb = visualize_grayscale(np.squeeze(image[:,:,0]))\n",
    "    predict= predict.astype(np.uint8)\n",
    "    predict= predict[:,:,np.newaxis]\n",
    "    intersect_mask = mask*predict\n",
    "    only_mask = np.where((mask-intersect_mask)==1, 1, 0)\n",
    "    only_pred = np.where((predict-intersect_mask)==1, 1, 0)\n",
    "    tp_np_mask = np.concatenate([only_pred,intersect_mask,only_mask], axis=-1)*255\n",
    "    vis = image_rgb/2 + tp_np_mask/2\n",
    "    vis = vis.astype(np.uint8)\n",
    "    visualize(image=image_rgb, result=tp_np_mask, visualize= vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_idx = int(val_dataset_idx[np.argmax(val_dataset_dice)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(val_dataset_dice))\n",
    "#red:FalsePositive / green:TruePositive / blue:FalseNegative\n",
    "i = max_idx\n",
    "image, mask = vis_val_dataset[i] \n",
    "predict= predict_masks[i]\n",
    "image_rgb = visualize_grayscale(np.squeeze(image[:,:,0]))\n",
    "predict= predict.astype(np.uint8)\n",
    "predict= predict[:,:,np.newaxis]\n",
    "intersect_mask = mask*predict\n",
    "only_mask = np.where((mask-intersect_mask)==1, 1, 0)\n",
    "only_pred = np.where((predict-intersect_mask)==1, 1, 0)\n",
    "tp_np_mask = np.concatenate([only_pred,intersect_mask,only_mask], axis=-1)*255\n",
    "vis = image_rgb/2 + tp_np_mask/2\n",
    "vis = vis.astype(np.uint8)\n",
    "visualize(image=image_rgb, result=tp_np_mask, visualize= vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"./ADC_ckpt/2d_ckpt/Deeplabv3plus_b0\"\n",
    "gen_new_dir(save_path)\n",
    "###############################\n",
    "trial = 2\n",
    "n_epoches = 10000\n",
    "LR = 0.0001\n",
    "LR_DECREASE = 1e-5\n",
    "lr_decrease_epoch = 70\n",
    "BATCH_SIZE = 64\n",
    "patience= 15\n",
    "###############################\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, \n",
    "                                           shuffle=True, drop_last=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=8, \n",
    "                                         shuffle=False)\n",
    "#timm-resnest101e\n",
    "#timm-efficientnet-b0\n",
    "#timm-efficientnet-b2\n",
    "#timm-efficientnet-b5\n",
    "#se_resnext50_32x4d\n",
    "#se_resnext101_32x4d\n",
    "#resnet152\n",
    "#densenet121\n",
    "#densenet169\n",
    "\n",
    "ENCODER = 'timm-efficientnet-b0'\n",
    "ACTIVATION = 'sigmoid' # could be None for logits or 'softmax2d' for multicalss segmentation\n",
    "DEVICE = 'cuda'\n",
    "\n",
    "# create segmentation model with pretrained encoder\n",
    "save_path = \"./ADC_ckpt/2d_ckpt/Deeplabv3plus_b0\"\n",
    "model = torch.load(os.path.join(save_path, 'best_model01.pth'))\n",
    "\n",
    "loss = smp.utils.losses.DiceLoss()\n",
    "\n",
    "metrics = [\n",
    "    smp.utils.metrics.IoU(threshold=0.5),\n",
    "]\n",
    "\n",
    "optimizer = torch.optim.Adam([ \n",
    "    dict(params=model.parameters(), lr=LR),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create epoch runners \n",
    "# it is a simple loop of iterating over dataloader`s samples\n",
    "train_epoch = smp.utils.train.TrainEpoch(\n",
    "    model, \n",
    "    loss=loss, \n",
    "    metrics=metrics, \n",
    "    optimizer=optimizer,\n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "valid_epoch = smp.utils.train.ValidEpoch(\n",
    "    model, \n",
    "    loss=loss, \n",
    "    metrics=metrics, \n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model for 40 epochs\n",
    "\n",
    "max_score = 0\n",
    "with open(os.path.join(save_path, f'results{str(trial).zfill(2)}.csv'), 'w') as f:\n",
    "    f.write('epoch,train_loss,train_score,valid_loss,valid_score\\n')\n",
    "\n",
    "early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
    "\n",
    "for epoch in range(0, n_epoches):\n",
    "    \n",
    "    print(f'\\nEpoch: {epoch}')\n",
    "    train_logs = train_epoch.run(train_loader)\n",
    "    valid_logs = valid_epoch.run(val_loader)\n",
    "    \n",
    "    with open(os.path.join(save_path, f'results{str(trial).zfill(2)}.csv'), 'a') as f:\n",
    "            f.write('%03d,%0.6f,%0.6f,%0.6f,%0.6f\\n' % (\n",
    "                (epoch + 1),\n",
    "                train_logs['dice_loss'],\n",
    "                train_logs['iou_score'],\n",
    "                valid_logs['dice_loss'],\n",
    "                valid_logs['iou_score'],\n",
    "            ))\n",
    "    \n",
    "    # do something (save model, change lr, etc.)\n",
    "    if max_score < valid_logs['iou_score']:\n",
    "        max_score = valid_logs['iou_score']\n",
    "        torch.save(model, os.path.join(save_path, f'best_model{str(trial).zfill(2)}.pth'))\n",
    "        print('New Record!')\n",
    "        \n",
    "    torch.save(model, os.path.join(save_path, f'final_model{str(trial).zfill(2)}.pth'))\n",
    "    \n",
    "    early_stopping(valid_logs['dice_loss'], model)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "    \n",
    "    if epoch == lr_decrease_epoch:\n",
    "        optimizer.param_groups[0]['lr'] = LR_DECREASE\n",
    "        print(f'Decrease decoder learning rate to {LR_DECREASE}!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
