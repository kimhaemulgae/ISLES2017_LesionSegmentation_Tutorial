{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import PIL.Image as Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "FILE_EXTENSION = ['.png', '.PNG', '.jpg', '.JPG', '.dcm', '.DCM', '.raw', '.RAW', '.svs', '.SVS']\n",
    "IMG_EXTENSION = ['.png', '.PNG', '.jpg', '.JPG', '.jpeg', '.JPEG']\n",
    "DCM_EXTENSION = ['.dcm', '.DCM']\n",
    "RAW_EXTENSION = ['.raw', '.RAW']\n",
    "NIFTI_EXTENSION = ['.nii']\n",
    "NP_EXTENSION = ['.npy']\n",
    "\n",
    "common_dir = '/home/ncp/workspace/202002n050/050.신경계 질환 관련 임상 및 진료 데이터'\n",
    "\n",
    "\n",
    "def check_extension(filename, extension_ls=FILE_EXTENSION):\n",
    "    return any(filename.endswith(extension) for extension in extension_ls)\n",
    "\n",
    "\n",
    "def load_file_path(folder_path, extension_ls=FILE_EXTENSION, all_sub_folders=False):\n",
    "    \"\"\"find 'IMG_EXTENSION' file paths in folder.\n",
    "    \n",
    "    Parameters:\n",
    "        folder_path (str) -- folder directory\n",
    "        extension_ls (list) -- list of extensions\n",
    "    \n",
    "    Return:\n",
    "        file_paths (list) -- list of 'extension_ls' file paths\n",
    "    \"\"\"\n",
    "    \n",
    "    file_paths = []\n",
    "    assert os.path.isdir(folder_path), f'{folder_path} is not a valid directory'\n",
    "\n",
    "    for root, _, fnames in sorted(os.walk(folder_path)):\n",
    "        for fname in fnames:\n",
    "            if check_extension(fname, extension_ls):\n",
    "                path = os.path.join(root, fname)\n",
    "                file_paths.append(path)\n",
    "        if not all_sub_folders:\n",
    "            break\n",
    "\n",
    "    return file_paths[:]\n",
    "\n",
    "\n",
    "def gen_new_dir(new_dir):\n",
    "    try: \n",
    "        if not os.path.exists(new_dir): \n",
    "            os.makedirs(new_dir) \n",
    "            #print(f\"New directory!: {new_dir}\")\n",
    "    except OSError: \n",
    "        print(\"Error: Failed to create the directory.\")\n",
    "        \n",
    "def get_data_fname_label_in_split(data_df, mode='train'):\n",
    "    return data_df[data_df['split_811']==mode][['name', 'bad_outcome_3m']].values\n",
    "\n",
    "\n",
    "def get_dataset(data_df, data_dir, mask_dir, mode='train'):\n",
    "    data_fname_label_arr = get_data_fname_label_in_split(data_df, mode=mode)\n",
    "    dwi_path_ls = sorted(load_file_path(os.path.join(data_dir, 'dwi'), NP_EXTENSION))\n",
    "    adc_path_ls = sorted(load_file_path(os.path.join(data_dir, 'adc'), NP_EXTENSION))\n",
    "    np_mask_path_ls = sorted(load_file_path(mask_dir, NP_EXTENSION))\n",
    "    dwi_path_dict = {os.path.splitext(os.path.basename(p))[0]:p for p in dwi_path_ls}\n",
    "    adc_path_dict = {os.path.splitext(os.path.basename(p))[0]:p for p in adc_path_ls}\n",
    "    np_mask_path_dict = {os.path.splitext(os.path.basename(p))[0]:p for p in np_mask_path_ls}\n",
    "    return [[dwi_path_dict.get(fname), adc_path_dict.get(fname), np_mask_path_dict.get(fname), label] \n",
    "            for fname, label in data_fname_label_arr if np_mask_path_dict.get(fname) if adc_path_dict.get(fname) if dwi_path_dict.get(fname)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir='/home/ncp/workspace/blocks1/dicom_to_np_2dnorm_resample'\n",
    "mask_dir='/home/ncp/workspace/blocks1/refined_mask_resample'\n",
    "data_df=pd.read_csv('/home/ncp/workspace/blocks1/aihub_df_new.csv')\n",
    "train_dataset_path = np.array(get_dataset(data_df, data_dir, mask_dir, mode='train'))\n",
    "val_dataset_path = np.array(get_dataset(data_df, data_dir, mask_dir, mode='val'))\n",
    "test_dataset_path = np.array(get_dataset(data_df, data_dir, mask_dir, mode='test'))\n",
    "all_dataset_path = np.concatenate([train_dataset_path[:,0], val_dataset_path[:,0], test_dataset_path[:,0]])\n",
    "dataset_fname_list = [os.path.splitext(os.path.basename(p))[0] for p in all_dataset_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['dwi_adc'] = data_df['name'].map(lambda x: True if x in dataset_fname_list else False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_df.to_csv('/home/ncp/workspace/blocks1/aihub_df_v.1.1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df[(data_df.dwi_adc == True) & (data_df.split_811 == 'train')].bad_outcome_3m.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df[(data_df.dwi_adc == True) & (data_df.split_811 == 'val')].bad_outcome_3m.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df[(data_df.dwi_adc == True) & (data_df.split_811 == 'test')].bad_outcome_3m.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df[(data_df.dwi_adc == True) & (data_df.split_811 != 'train')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_test_info = data_df[(data_df.dwi_adc == True) & (data_df.split_811 != 'train')][['name', 'bad_outcome_3m']].values\n",
    "tot_fname = val_test_info[:,0]\n",
    "tot_label = val_test_info[:,1]\n",
    "\n",
    "val_fname, test_fname, val_label, test_label = train_test_split(tot_fname, \n",
    "                                                                tot_label, \n",
    "                                                                test_size=0.5, \n",
    "                                                                random_state=17, # 17\n",
    "                                                                stratify=tot_label) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'brain_mri_2013-3663' in test_fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_test_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_fname), len(test_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_val_test(fname, tmp, val_fname, test_fname):\n",
    "    if fname in val_fname:\n",
    "        return 'val'\n",
    "    elif fname in test_fname:\n",
    "        return 'test'\n",
    "    \n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_val_test(fname, 'train', val_fname, test_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.name.values[20] in test_fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['split_811_new'] = data_df.apply(lambda x: split_val_test(x['name'], x['split_811'], val_fname, test_fname), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df[(data_df.split_811 == 'val') & (data_df.split_811_new == 'test')].name.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_case = ['brain_mri_2013-0184', \n",
    "              'brain_mri_2013-0515', \n",
    "              'brain_mri_2013-0079', \n",
    "              'brain_mri_2013-3391', \n",
    "              'brain_mri_2013-0041', \n",
    "              'brain_mri_2013-1318', \n",
    "              'brain_mri_2013-0999', \n",
    "              'brain_mri_2013-3481']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df[data_df.name == 'brain_mri_2013-3669']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_stack(stack, rows=6, cols=6, start_with=0, show_every=1):\n",
    "    try:\n",
    "        fig,ax = plt.subplots(rows,cols,figsize=[18,20])\n",
    "        for i in range(rows*cols):\n",
    "            ind = start_with + i*show_every\n",
    "            ax[int(i/cols), int(i%cols)].set_title(f'slice {ind}')\n",
    "\n",
    "            ax[int(i/cols), int(i%cols)].imshow(stack[ind],cmap='gray', vmin=0, vmax=255)#, vmin=0, vmax=255\n",
    "            ax[int(i/cols), int(i%cols)].axis('off')\n",
    "        plt.show()\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('/home/ncp/workspace/blocks1/dicom_to_np_2dnorm_resample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_df.to_csv('/home/ncp/workspace/blocks1/aihub_df_v.1.2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_df = pd.read_csv('/home/ncp/workspace/AIHUB_dataset/df_csv_merged_v2.1.1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_info = data_df[(data_df.dwi_adc == True) & (data_df.split_811_new == 'train')][['name', 'bad_outcome_3m']].values\n",
    "val_info = data_df[(data_df.dwi_adc == True) & (data_df.split_811_new == 'val')][['name', 'bad_outcome_3m']].values\n",
    "test_info = data_df[(data_df.dwi_adc == True) & (data_df.split_811_new == 'test')][['name', 'bad_outcome_3m']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_info_arr = []\n",
    "label_arr = []\n",
    "for f_path, label in train_info:\n",
    "    fname = os.path.splitext(os.path.basename(f_path))[0]\n",
    "    tabular_info = tabular_df[tabular_df.name == fname][['pre_good_mrs', 'age_cate', 'ini_nih', 'END', 'hx_str']].values\n",
    "    tabular_info_arr.append(tabular_info)\n",
    "    label_arr.append(label)\n",
    "tabular_info_arr = np.array(tabular_info_arr)\n",
    "label_arr = np.array(label_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.squeeze(tabular_info_arr)\n",
    "Y_train = label_arr\n",
    "XY_train_df = pd.DataFrame(np.hstack([X_train, Y_train[:,np.newaxis]]))\n",
    "XY_train_df.dropna(axis=0, inplace=True, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_info_arr = []\n",
    "label_arr = []\n",
    "for f_path, label in val_info:\n",
    "    fname = os.path.splitext(os.path.basename(f_path))[0]\n",
    "    tabular_info = tabular_df[tabular_df.name == fname][['pre_good_mrs', 'age_cate', 'ini_nih', 'END', 'hx_str']].values\n",
    "    tabular_info_arr.append(tabular_info)\n",
    "    label_arr.append(label)\n",
    "tabular_info_arr = np.array(tabular_info_arr)\n",
    "label_arr = np.array(label_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = np.squeeze(tabular_info_arr)\n",
    "Y_val = label_arr\n",
    "XY_val_df = pd.DataFrame(np.hstack([X_val, Y_val[:,np.newaxis]]))\n",
    "XY_val_df.dropna(axis=0, inplace=True, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.splitext(os.path.basename('ksssd.ns'))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_info_arr = []\n",
    "label_arr = []\n",
    "for f_path, label in test_info:\n",
    "    fname = os.path.splitext(os.path.basename(f_path))[0]\n",
    "    tabular_info = tabular_df[tabular_df.name == fname][['pre_good_mrs', 'age_cate', 'ini_nih', 'END', 'hx_str']].values\n",
    "    tabular_info_arr.append(tabular_info)\n",
    "    label_arr.append(label)\n",
    "tabular_info_arr = np.array(tabular_info_arr)\n",
    "label_arr = np.array(label_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.squeeze(tabular_info_arr)\n",
    "Y_test = label_arr\n",
    "XY_test_df = pd.DataFrame(np.hstack([X_test, Y_test[:,np.newaxis]]))\n",
    "XY_test_df.dropna(axis=0, inplace=True, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf_only_ci = RandomForestClassifier(n_estimators=500,max_depth=5)\n",
    "model_rf_only_ci.fit(XY_train_df.iloc[:,:5], XY_train_df.iloc[:,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_proba = model_rf_only_ci.predict_proba(XY_test_df.iloc[:,:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(Y_test==1, out_proba[:,1])\n",
    "J = tpr - fpr # Youden's J statistic\n",
    "idx = np.argmax(J)\n",
    "best_thresh = thresholds[idx]\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "sens, spec = tpr[idx], 1-fpr[idx]\n",
    "print(f\"ROCAUC:\\t\\t\\t\\t\\t{roc_auc}\")\n",
    "print(f\"Best threshold(Youden's J statistic):\\t{best_thresh}\")\n",
    "print(f\"Sensitivity:\\t\\t\\t\\t{sens}\")\n",
    "print(f\"Specificity:\\t\\t\\t\\t{spec}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_proba = model_rf_only_ci.predict_proba(XY_val_df.iloc[:,:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(Y_val==1, out_proba[:,1])\n",
    "J = tpr - fpr # Youden's J statistic\n",
    "idx = np.argmax(J)\n",
    "best_thresh = thresholds[idx]\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "sens, spec = tpr[idx], 1-fpr[idx]\n",
    "print(f\"ROCAUC:\\t\\t\\t\\t\\t{roc_auc}\")\n",
    "print(f\"Best threshold(Youden's J statistic):\\t{best_thresh}\")\n",
    "print(f\"Sensitivity:\\t\\t\\t\\t{sens}\")\n",
    "print(f\"Specificity:\\t\\t\\t\\t{spec}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
