{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import PIL.Image as Image\n",
    "\n",
    "FILE_EXTENSION = ['.png', '.PNG', '.jpg', '.JPG', '.dcm', '.DCM', '.raw', '.RAW', '.svs', '.SVS']\n",
    "IMG_EXTENSION = ['.png', '.PNG', '.jpg', '.JPG', '.jpeg', '.JPEG']\n",
    "DCM_EXTENSION = ['.dcm', '.DCM']\n",
    "RAW_EXTENSION = ['.raw', '.RAW']\n",
    "NIFTI_EXTENSION = ['.nii']\n",
    "NP_EXTENSION = ['.npy']\n",
    "\n",
    "mask_common_dir = '/home/ncp/workspace/202002n050/050.신경계 질환 관련 임상 및 진료 데이터'\n",
    "\n",
    "\n",
    "def check_extension(filename, extension_ls=FILE_EXTENSION):\n",
    "    return any(filename.endswith(extension) for extension in extension_ls)\n",
    "\n",
    "\n",
    "def load_file_path(folder_path, extension_ls=FILE_EXTENSION, all_sub_folders=False):\n",
    "    \"\"\"find 'IMG_EXTENSION' file paths in folder.\n",
    "    \n",
    "    Parameters:\n",
    "        folder_path (str) -- folder directory\n",
    "        extension_ls (list) -- list of extensions\n",
    "    \n",
    "    Return:\n",
    "        file_paths (list) -- list of 'extension_ls' file paths\n",
    "    \"\"\"\n",
    "    \n",
    "    file_paths = []\n",
    "    assert os.path.isdir(folder_path), f'{folder_path} is not a valid directory'\n",
    "\n",
    "    for root, _, fnames in sorted(os.walk(folder_path)):\n",
    "        for fname in fnames:\n",
    "            if check_extension(fname, extension_ls):\n",
    "                path = os.path.join(root, fname)\n",
    "                file_paths.append(path)\n",
    "        if not all_sub_folders:\n",
    "            break\n",
    "\n",
    "    return file_paths[:]\n",
    "\n",
    "\n",
    "def gen_new_dir(new_dir):\n",
    "    try: \n",
    "        if not os.path.exists(new_dir): \n",
    "            os.makedirs(new_dir) \n",
    "            #print(f\"New directory!: {new_dir}\")\n",
    "    except OSError: \n",
    "        print(\"Error: Failed to create the directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data preprocessing ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_aihub_img_dir(common_dir, fname, folder='train'):\n",
    "    if folder == 'train':\n",
    "        img_dir = os.path.join(common_dir, '01.데이터/1.Training/원천데이터', fname, 'init/image')\n",
    "    elif folder == 'val':\n",
    "        img_dir = os.path.join(common_dir, '01.데이터/2.Validation/원천데이터', fname, 'init/image')\n",
    "    else:\n",
    "        return None\n",
    "    return img_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MR_SEQUENCE = {'T2' : '*ep_b0', \n",
    "               'DWI' : '*ep_b1000t', \n",
    "               'ADC' : '*ep_b0_1000'}\n",
    "\n",
    "\n",
    "def find_aihub_dicom_dir(common_dir, fname, folder='train'):\n",
    "    if folder == 'train':\n",
    "        dicom_dir = os.path.join(common_dir, '01.데이터/1.Training/원천데이터', fname, 'init')\n",
    "    elif folder == 'val':\n",
    "        dicom_dir = os.path.join(common_dir, '01.데이터/2.Validation/원천데이터', fname, 'init')\n",
    "    else:\n",
    "        return None\n",
    "    return dicom_dir\n",
    "\n",
    "\n",
    "def get_aihub_case_name(common_dir, folder='train'):\n",
    "    if folder=='train':\n",
    "        data_dir = os.path.join(common_dir, '01.데이터/1.Training/원천데이터')\n",
    "    elif folder=='val':\n",
    "        data_dir = os.path.join(common_dir, '01.데이터/2.Validation/원천데이터')\n",
    "        \n",
    "    _fname = os.listdir(data_dir)\n",
    "    _fname = [p for p in _fname if os.path.isdir(os.path.join(data_dir, p))]\n",
    "    \n",
    "    return _fname\n",
    "\n",
    "\n",
    "def check_aihub_mr_scans(patient_folder_path, norm=True, sequence='DWI'):\n",
    "    dcm_paths = sorted(load_file_path(patient_folder_path, DCM_EXTENSION))\n",
    "    \n",
    "    sequence_dcm_paths = [[dcm_path, pydicom.read_file(dcm_path, force=True)] for dcm_path in dcm_paths]\n",
    "    sequence_dcm_paths = [p for p, s in sequence_dcm_paths if MR_SEQUENCE[sequence] == s.get('SequenceName')]\n",
    "#     dcm_paths = sorted(load_file_path(patient_folder_path, DCM_EXTENSION))\n",
    "    \n",
    "#     sequence_dcm_paths = []\n",
    "#     for dcm_path in dcm_paths:\n",
    "#         tmp_info = pydicom.read_file(dcm_path, defer_size='20KB', force=True)\n",
    "#         if MR_SEQUENCE[sequence] == tmp_info.get(\"Sequence Name\"):\n",
    "#             sequence_dcm_paths.append(dcm_path)\n",
    "        \n",
    "    return sequence_dcm_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre_good_mrs, age, ini_nih, END, hx_str\n",
    "# good outcome -> bad outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aihub_df = pd.read_csv('/home/ncp/workspace/AIHUB_dataset/df_csv_merged_v2.1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_aihub_img_mask_fname(common_dir, folder='train'):\n",
    "    if folder=='train':\n",
    "        data_dir = os.path.join(common_dir, '01.데이터/1.Training/원천데이터')\n",
    "    elif folder=='val':\n",
    "        data_dir = os.path.join(common_dir, '01.데이터/2.Validation/원천데이터')\n",
    "        \n",
    "    _fname = os.listdir(data_dir)\n",
    "    _fname = [p for p in _fname if os.path.isdir(os.path.join(data_dir, p))]\n",
    "    return _fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fname = find_aihub_img_mask_fname(common_dir, folder='train')\n",
    "val_fname = find_aihub_img_mask_fname(common_dir, folder='val')\n",
    "def check_folder_dir(fname):\n",
    "    if fname in train_fname:\n",
    "        return 'train'\n",
    "    elif fname in val_fname:\n",
    "        return 'val'\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def split_train_val_test(fname):\n",
    "    if fname in train_fname:\n",
    "        return 'train'\n",
    "    elif fname in val_fname:\n",
    "        return 'val'\n",
    "    elif fname in test_fname:\n",
    "        return 'test'\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_aihub_df = aihub_df[['name', 'good_outcome_3m', 'mrs_3m', 'mrs3mo', 'END', 'excel_outcome_3m', 'ini_nih']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_aihub_df['folder'] = pred_aihub_df['name'].map(lambda x: check_folder_dir(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_aihub_df_clear = pred_aihub_df.copy()\n",
    "pred_aihub_df_clear['mrs_3m'] = pred_aihub_df['mrs_3m'].fillna(value=pred_aihub_df.mrs3mo)\n",
    "pred_aihub_df_clear = pred_aihub_df_clear[['name', 'good_outcome_3m', 'mrs_3m', 'END', 'excel_outcome_3m', 'ini_nih', 'folder']]\n",
    "pred_aihub_df_clear.isna().sum()\n",
    "pred_aihub_df_clear = pred_aihub_df_clear.dropna(axis=0)\n",
    "pred_aihub_df_clear = pred_aihub_df_clear.astype({'good_outcome_3m' : int,\n",
    "                                                  'mrs_3m' : int,\n",
    "                                                 'excel_outcome_3m' : int})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_fname_label = pred_aihub_df_clear[['name', 'good_outcome_3m']].values\n",
    "tot_fname = tot_fname_label[:,0]\n",
    "tot_label = tot_fname_label[:,1]\n",
    "train_fname, valtest_fname, train_label, valtest_label = train_test_split(tot_fname, \n",
    "                                                                    tot_label, \n",
    "                                                                    test_size=0.2, \n",
    "                                                                    random_state=77, \n",
    "                                                                    stratify=tot_label)\n",
    "val_fname, test_fname, val_label, test_label = train_test_split(valtest_fname, \n",
    "                                                                valtest_label, \n",
    "                                                                test_size=0.5, \n",
    "                                                                random_state=77, \n",
    "                                                                stratify=valtest_label) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_val_test(fname):\n",
    "    if fname in train_fname:\n",
    "        return 'train'\n",
    "    elif fname in val_fname:\n",
    "        return 'val'\n",
    "    elif fname in test_fname:\n",
    "        return 'test'\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_aihub_df_clear['split_811'] = pred_aihub_df_clear['name'].map(lambda x: split_train_val_test(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_aihub_df_clear[pred_aihub_df_clear.split_811 == 'train']['mrs_3m'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_mrs_3m_9 = pred_aihub_df_clear[pred_aihub_df_clear.mrs_3m == 9].index\n",
    "pred_aihub_df_clear = pred_aihub_df_clear.drop(idx_mrs_3m_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_aihub_df_clear.to_csv('/home/ncp/workspace/blocks1/aihub_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aihub_df = pd.read_csv('/home/ncp/workspace/blocks1/aihub_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcm_exist_list_0 = []\n",
    "folder = 'val'\n",
    "case_name_ls = get_aihub_case_name(common_dir, folder=folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcm_exist_list_0 = []\n",
    "folder = 'val'\n",
    "case_name_ls = get_aihub_case_name(common_dir, folder=folder)\n",
    "for N in tqdm(range(len(case_name_ls))):\n",
    "    \n",
    "    sample_case_name = case_name_ls[N]\n",
    "    sample_case_png_dir = find_aihub_img_dir(common_dir, sample_case_name, folder=folder)\n",
    "    sample_case_dicom_dir = find_aihub_dicom_dir(common_dir, sample_case_name, folder=folder)\n",
    "\n",
    "    if sample_case_dicom_dir:\n",
    "        if os.path.isdir(sample_case_png_dir):\n",
    "            png_len = len(load_file_path(sample_case_png_dir, IMG_EXTENSION))\n",
    "            sample_dicom_list = load_file_path(sample_case_dicom_dir, DCM_EXTENSION)\n",
    "            sample_seq_dwi_list = check_aihub_mr_scans(sample_case_dicom_dir, sequence='DWI')\n",
    "            sample_seq_adc_list = check_aihub_mr_scans(sample_case_dicom_dir, sequence='ADC')\n",
    "            if (png_len == len(sample_seq_dwi_list)) & (png_len == len(sample_seq_adc_list)):\n",
    "                dcm_exist_list_0.append(sample_case_name)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcm_exist_list = []\n",
    "folder = 'train'\n",
    "case_name_ls = get_aihub_case_name(common_dir, folder=folder)\n",
    "for N in tqdm(range(len(case_name_ls))):\n",
    "    \n",
    "    sample_case_name = case_name_ls[N]\n",
    "    sample_case_png_dir = find_aihub_img_dir(common_dir, sample_case_name, folder=folder)\n",
    "    sample_case_dicom_dir = find_aihub_dicom_dir(common_dir, sample_case_name, folder=folder)\n",
    "\n",
    "    if sample_case_dicom_dir:\n",
    "        if os.path.isdir(sample_case_png_dir):\n",
    "            png_len = len(load_file_path(sample_case_png_dir, IMG_EXTENSION))\n",
    "            sample_dicom_list = load_file_path(sample_case_dicom_dir, DCM_EXTENSION)\n",
    "            sample_seq_dwi_list = check_aihub_mr_scans(sample_case_dicom_dir, sequence='DWI')\n",
    "            sample_seq_adc_list = check_aihub_mr_scans(sample_case_dicom_dir, sequence='ADC')\n",
    "            if (png_len == len(sample_seq_dwi_list)) & (png_len == len(sample_seq_adc_list)):\n",
    "                dcm_exist_list.append(sample_case_name)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dicom_header_sequence(fname):\n",
    "    if fname in dcm_exist_list:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aihub_df['dcm_header_seq'] = aihub_df['name'].map(lambda x: check_dicom_header_sequence(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aihub_df.to_csv('/home/ncp/workspace/blocks1/3D_CNN_for_PRED/aihub_df_check_dwi.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_folder = aihub_df[aihub_df['dcm_header_seq'] == 0][['name', 'folder']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dwi_adc_in_fname(path_ls):\n",
    "    fname_path_ls = [[os.path.splitext(os.path.basename(p))[0].upper(), p] for p in path_ls]\n",
    "    dwi_path_ls = [p for fname, p in fname_path_ls if 'DW' in fname]\n",
    "    adc_path_ls = [p for fname, p in fname_path_ls if 'AD' in fname]\n",
    "    return sorted(dwi_path_ls), sorted(adc_path_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicom_exist_list_2 = []\n",
    "\n",
    "for N in tqdm(range(len(name_folder))):\n",
    "    name, folder = name_folder[N]\n",
    "    case_png_dir = find_aihub_img_dir(common_dir, name, folder=folder)\n",
    "    case_dicom_dir = find_aihub_dicom_dir(common_dir, name, folder=folder)\n",
    "    if os.path.isdir(case_dicom_dir):\n",
    "        case_dicom_paths = sorted(load_file_path(case_dicom_dir, DCM_EXTENSION))\n",
    "        case_first_dicom_fname = os.path.splitext(os.path.basename(case_dicom_paths[0]))[0].upper()\n",
    "        if 'AD' in case_first_dicom_fname:\n",
    "            if os.path.isdir(case_png_dir):\n",
    "                png_len = len(load_file_path(case_png_dir, IMG_EXTENSION))\n",
    "                dwi_path_ls, adc_path_ls = split_dwi_adc_in_fname(case_dicom_paths)\n",
    "                if png_len == len(dwi_path_ls):\n",
    "                    dicom_exist_list_2.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_fname_dwi_adc(fname):\n",
    "    if fname in dicom_exist_list_2:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aihub_df = aihub_df[['name', 'good_outcome_3m', 'mrs_3m', 'END', 'excel_outcome_3m', 'ini_nih', 'folder', 'split_811', 'split_311', 'dcm_header_seq']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aihub_df['fname_dwi_adc'] = aihub_df['name'].map(lambda x: check_fname_dwi_adc(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicom_exist_list_3 = []\n",
    "\n",
    "for N in tqdm(range(len(name_folder))):\n",
    "    name, folder = name_folder[N]\n",
    "    case_png_dir = find_aihub_img_dir(common_dir, name, folder=folder)\n",
    "    case_dicom_dir = find_aihub_dicom_dir(common_dir, name, folder=folder)\n",
    "    if os.path.isdir(case_dicom_dir):\n",
    "        case_dicom_paths = sorted(load_file_path(case_dicom_dir, DCM_EXTENSION))\n",
    "        case_first_dicom_fname = os.path.splitext(os.path.basename(case_dicom_paths[0]))[0].upper()\n",
    "        if 'AD' in case_first_dicom_fname:\n",
    "            if os.path.isdir(case_png_dir):\n",
    "                png_len = len(load_file_path(case_png_dir, IMG_EXTENSION))\n",
    "                dwi_path_ls, adc_path_ls = split_dwi_adc_in_fname(case_dicom_paths)\n",
    "                if png_len == int(len(dwi_path_ls)/2):\n",
    "                    \n",
    "                    dicom_exist_list_3.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_fname_dwi_adc_half(fname):\n",
    "    if fname in dicom_exist_list_3:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aihub_df['fname_dwi_adc_half'] = aihub_df['name'].map(lambda x: check_fname_dwi_adc_half(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aihub_df.groupby(['dcm_header_seq', 'fname_dwi_adc', 'fname_dwi_adc_half']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aihub_df.to_csv('/home/ncp/workspace/blocks1/aihub_df_define_dcm.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('/home/ncp/workspace/blocks1/aihub_df_define_dcm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aihub_df_dcm_failed = aihub_df[(aihub_df.dcm_header_seq==0)&(aihub_df.fname_dwi_adc==0)&(aihub_df.fname_dwi_adc_half==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_folder_dcm_fl = aihub_df_dcm_failed[['name', 'folder']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicom_exist_list_4 = []\n",
    "\n",
    "for N in tqdm(range(len(name_folder))):\n",
    "    name, folder = name_folder[N]\n",
    "    case_png_dir = find_aihub_img_dir(common_dir, name, folder=folder)\n",
    "    case_dicom_dir = find_aihub_dicom_dir(common_dir, name, folder=folder)\n",
    "    if os.path.isdir(case_dicom_dir):\n",
    "        case_dicom_paths = sorted(load_file_path(case_dicom_dir, DCM_EXTENSION))\n",
    "        case_first_dicom_fname = os.path.splitext(os.path.basename(case_dicom_paths[0]))[0].upper()\n",
    "        if 'DW' in case_first_dicom_fname:\n",
    "            if os.path.isdir(case_png_dir):\n",
    "                png_len = len(load_file_path(case_png_dir, IMG_EXTENSION))\n",
    "                dwi_path_ls, adc_path_ls = split_dwi_adc_in_fname(case_dicom_paths)\n",
    "                if png_len == int(len(dwi_path_ls)/2):\n",
    "                    \n",
    "                    dicom_exist_list_4.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_only_dwi_half(fname):\n",
    "    if fname in dicom_exist_list_4:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aihub_df['only_dwi_half'] = aihub_df['name'].map(lambda x: check_only_dwi_half(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicom_exist_list_5 = []\n",
    "\n",
    "for N in tqdm(range(len(name_folder))):\n",
    "    name, folder = name_folder[N]\n",
    "    case_png_dir = find_aihub_img_dir(common_dir, name, folder=folder)\n",
    "    case_dicom_dir = find_aihub_dicom_dir(common_dir, name, folder=folder)\n",
    "    if os.path.isdir(case_dicom_dir):\n",
    "        case_dicom_paths = sorted(load_file_path(case_dicom_dir, DCM_EXTENSION))\n",
    "        case_first_dicom_fname = os.path.splitext(os.path.basename(case_dicom_paths[0]))[0].upper()\n",
    "        if 'DW' in case_first_dicom_fname:\n",
    "            if os.path.isdir(case_png_dir):\n",
    "                png_len = len(load_file_path(case_png_dir, IMG_EXTENSION))\n",
    "                dwi_path_ls, adc_path_ls = split_dwi_adc_in_fname(case_dicom_paths)\n",
    "                if png_len == int(len(dwi_path_ls)):\n",
    "                    \n",
    "                    dicom_exist_list_5.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_only_dwi(fname):\n",
    "    if fname in dicom_exist_list_5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aihub_df['only_dwi'] = aihub_df['name'].map(lambda x: check_only_dwi(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_fname_dwi_adc_half(fname):\n",
    "    if fname in dicom_exist_list_3:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aihub_df['fname_dwi_adc_half'] = aihub_df['name'].map(lambda x: check_fname_dwi_adc_half(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_folder_dcm_fl = aihub_df_dcm_failed[['name', 'folder']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aihub_df_dcm_failed = aihub_df[(aihub_df.dcm_header_seq==0)&(aihub_df.fname_dwi_adc==0)&(aihub_df.fname_dwi_adc_half==0)&(aihub_df.only_dwi==0)&(aihub_df.only_dwi_half==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcm_failed_idx = aihub_df[(aihub_df.dcm_header_seq==0)&(aihub_df.fname_dwi_adc==0)&(aihub_df.fname_dwi_adc_half==0)&(aihub_df.only_dwi==0)&(aihub_df.only_dwi_half==0)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aihub_df_wo_failed = aihub_df.drop(dcm_failed_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aihub_df_wo_failed.to_csv('/home/ncp/workspace/blocks1/aihub_df_define_dcm_clear.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aihub_df.to_csv('/home/ncp/workspace/blocks1/aihub_df_define_dcm.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_name_folder = aihub_df[['name', 'folder']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_dicom_dict = {}\n",
    "\n",
    "\n",
    "for name, folder in tqdm(case_name_folder):\n",
    "    flag=True\n",
    "    if aihub_df[aihub_df.name == name].only_dwi.values == 1:\n",
    "        case_dicom_dir = find_aihub_dicom_dir(common_dir, name, folder=folder)\n",
    "        case_dicom_paths = sorted(load_file_path(case_dicom_dir, DCM_EXTENSION))\n",
    "        dwi_path_ls, _ = split_dwi_adc_in_fname(case_dicom_paths)\n",
    "        adc_path_ls=None\n",
    "    elif aihub_df[aihub_df.name == name].only_dwi_half.values == 1:\n",
    "        case_dicom_dir = find_aihub_dicom_dir(common_dir, name, folder=folder)\n",
    "        case_dicom_paths = sorted(load_file_path(case_dicom_dir, DCM_EXTENSION))\n",
    "        dwi_path_ls, _ = split_dwi_adc_in_fname(case_dicom_paths)\n",
    "        dwi_path_ls = dwi_path_ls[:int(len(dwi_path_ls)/2)]\n",
    "        adc_path_ls=None\n",
    "    elif aihub_df[aihub_df.name == name].fname_dwi_adc.values == 1:\n",
    "        case_dicom_dir = find_aihub_dicom_dir(common_dir, name, folder=folder)\n",
    "        case_dicom_paths = sorted(load_file_path(case_dicom_dir, DCM_EXTENSION))\n",
    "        dwi_path_ls, adc_path_ls = split_dwi_adc_in_fname(case_dicom_paths)\n",
    "    elif aihub_df[aihub_df.name == name].fname_dwi_adc_half.values == 1:\n",
    "        case_dicom_dir = find_aihub_dicom_dir(common_dir, name, folder=folder)\n",
    "        case_dicom_paths = sorted(load_file_path(case_dicom_dir, DCM_EXTENSION))\n",
    "        dwi_path_ls, adc_path_ls = split_dwi_adc_in_fname(case_dicom_paths)\n",
    "        dwi_path_ls = dwi_path_ls[:int(len(dwi_path_ls)/2)]\n",
    "    elif aihub_df[aihub_df.name == name].dcm_header_seq.values == 1:\n",
    "        case_dicom_dir = find_aihub_dicom_dir(common_dir, name, folder=folder)\n",
    "        dwi_path_ls = check_aihub_mr_scans(case_dicom_dir, sequence='DWI')\n",
    "        adc_path_ls = check_aihub_mr_scans(case_dicom_dir, sequence='ADC')\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    fname_dicom_dict[name]= [dwi_path_ls,adc_path_ls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('fname_dicom.pickle', 'wb') as fw:\n",
    "#     pickle.dump(fname_dicom_dict, fw)\n",
    "    \n",
    "with open('fname_dicom.pickle', 'rb') as fr:\n",
    "    fname_dicom_dict_load = pickle.load(fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('fname_dicom.pickle', 'rb') as fr:\n",
    "    fname_dicom_dict_load = pickle.load(fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get 2d lesion area ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(os.listdir('/home/ncp/workspace/blocks1/dicom_to_png_2d/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_2d_mask_3dim(mask_path_ls):\n",
    "    mask_path_ls = sorted(mask_path_ls)\n",
    "    return np.stack([np.array(Image.open(p)) for p in mask_path_ls], axis=0) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_dir = '/home/ncp/workspace/blocks1/dicom_to_png_2d/'\n",
    "predicted_lesion_area_ls = []\n",
    "for fname in tqdm(os.listdir(common_dir)):\n",
    "    mask_dir = os.path.join(common_dir, fname, 'pred_masks')\n",
    "    mask_path_ls = load_file_path(mask_dir, IMG_EXTENSION)\n",
    "    if len(mask_path_ls) > 0:\n",
    "        mask_3d = read_2d_mask_3dim(mask_path_ls)\n",
    "        \n",
    "        predicted_lesion_area_ls.append([fname, np.sum(mask_3d)/(mask_3d.shape[0]*256*256)*10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lesion_area_df = pd.DataFrame(predicted_lesion_area_ls, columns=['name', 'pred_lesion_area'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pred_lesion_area_df.to_csv('/home/ncp/workspace/blocks2/pred_lesion_area_df_og.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lesion_area_df.pred_lesion_area.values.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_df = pd.read_csv('/home/ncp/workspace/AIHUB_dataset/df_csv_merged_v2.1.1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv('/home/ncp/workspace/blocks1/aihub_df_v.1.2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_info_arr = []\n",
    "label_arr = []\n",
    "for f_path, _, _, label in test_dataset.dataset:\n",
    "    fname = os.path.splitext(os.path.basename(f_path))[0]\n",
    "    tabular_info = tabular_df[tabular_df.name == fname][['pre_good_mrs', 'age_cate', 'ini_nih', 'END', 'hx_str']].values\n",
    "    tabular_info_arr.append(tabular_info)\n",
    "    label_arr.append(label)\n",
    "tabular_info_arr = np.array(tabular_info_arr)\n",
    "label_arr = np.array(label_arr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
