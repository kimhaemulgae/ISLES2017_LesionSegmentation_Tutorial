{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import PIL.Image as Image\n",
    "\n",
    "import nibabel as nib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "from util.util import *\n",
    "from util.visualize import *\n",
    "from data.dataset_2d import *\n",
    "\n",
    "common_dir = '/home/ncp/workspace/202002n050/050.신경계 질환 관련 임상 및 진료 데이터'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "FILE_EXTENSION = ['.png', '.PNG', '.jpg', '.JPG', '.dcm', '.DCM', '.raw', '.RAW', '.svs', '.SVS']\n",
    "IMG_EXTENSION = ['.png', '.PNG', '.jpg', '.JPG', '.jpeg', '.JPEG']\n",
    "DCM_EXTENSION = ['.dcm', '.DCM']\n",
    "RAW_EXTENSION = ['.raw', '.RAW']\n",
    "NIFTI_EXTENSION = ['.nii']\n",
    "NP_EXTENSION = ['.npy']\n",
    "\n",
    "mask_common_dir = '/home/ncp/workspace/202002n050/050.신경계 질환 관련 임상 및 진료 데이터'\n",
    "\n",
    "\n",
    "def check_extension(filename, extension_ls=FILE_EXTENSION):\n",
    "    return any(filename.endswith(extension) for extension in extension_ls)\n",
    "\n",
    "\n",
    "def load_file_path(folder_path, extension_ls=FILE_EXTENSION, all_sub_folders=False):\n",
    "    \"\"\"find 'IMG_EXTENSION' file paths in folder.\n",
    "    \n",
    "    Parameters:\n",
    "        folder_path (str) -- folder directory\n",
    "        extension_ls (list) -- list of extensions\n",
    "    \n",
    "    Return:\n",
    "        file_paths (list) -- list of 'extension_ls' file paths\n",
    "    \"\"\"\n",
    "    \n",
    "    file_paths = []\n",
    "    assert os.path.isdir(folder_path), f'{folder_path} is not a valid directory'\n",
    "\n",
    "    for root, _, fnames in sorted(os.walk(folder_path)):\n",
    "        for fname in fnames:\n",
    "            if check_extension(fname, extension_ls):\n",
    "                path = os.path.join(root, fname)\n",
    "                file_paths.append(path)\n",
    "        if not all_sub_folders:\n",
    "            break\n",
    "\n",
    "    return file_paths[:]\n",
    "\n",
    "\n",
    "def gen_new_dir(new_dir):\n",
    "    try: \n",
    "        if not os.path.exists(new_dir): \n",
    "            os.makedirs(new_dir) \n",
    "            #print(f\"New directory!: {new_dir}\")\n",
    "    except OSError: \n",
    "        print(\"Error: Failed to create the directory.\")\n",
    "\n",
    "\n",
    "def find_dwi_adc_mask_dir(img_folder_dir, fname):\n",
    "    dwi_folder_dir = os.path.join(img_folder_dir, fname, 'dwi')\n",
    "    adc_folder_dir = os.path.join(img_folder_dir, fname, 'adc')\n",
    "    mask_folder_dir = os.path.join(img_folder_dir, fname, 'pred_masks')\n",
    "    if (os.path.isdir(dwi_folder_dir)) & (os.path.isdir(adc_folder_dir)):\n",
    "        return dwi_folder_dir, adc_folder_dir, mask_folder_dir\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_data_fname_label_in_split(data_df, mode='train'):\n",
    "    return data_df[data_df['split']==mode][['name', 'good_outcome_3m']].values\n",
    "\n",
    "\n",
    "def get_dataset(data_df, data_dir, mode='train'):\n",
    "    data_fname_label_arr = get_data_fname_label_in_split(data_df, mode=mode)\n",
    "\n",
    "\n",
    "def pair_aihub_dwi_adc_mask_img_label_path(img_folder_dir, data_df):\n",
    "    img_label_path_dict = {}\n",
    "    for fname in sorted(data_df.name.values):\n",
    "        dwi_adc_mask_dir = find_dwi_adc_mask_dir(img_folder_dir, fname)\n",
    "        label = data_df[data_df.name==fname]['bad_outcome_3m'].values[0]\n",
    "        if dwi_adc_mask_dir:\n",
    "            dwi_folder_dir, adc_folder_dir, mask_folder_dir = dwi_adc_mask_dir\n",
    "            dwi_path_ls = sorted(load_file_path(dwi_folder_dir, IMG_EXTENSION))\n",
    "            adc_path_ls = sorted(load_file_path(adc_folder_dir, IMG_EXTENSION))\n",
    "            mask_path_ls = sorted(load_file_path(mask_folder_dir, IMG_EXTENSION))\n",
    "            img_path_ls = list(zip(dwi_path_ls,adc_path_ls, mask_path_ls))\n",
    "            \n",
    "            img_label_path_dict[fname] = [img_path_ls, label]\n",
    "    return img_label_path_dict\n",
    "\n",
    "\n",
    "def select_train_val_test(img_mask_path_dict, fname_list):\n",
    "    tmp_dict = {}\n",
    "    for fname in fname_list:\n",
    "        if img_mask_path_dict.get(fname):\n",
    "            tmp_dict[fname] = img_mask_path_dict.get(fname)\n",
    "            \n",
    "    return tmp_dict\n",
    "\n",
    "\n",
    "def find_aihub_img_label_paths(img_folder_dir, data_df, fname_list):\n",
    "    img_label_path_dict = pair_aihub_dwi_adc_mask_img_label_path(img_folder_dir, data_df)\n",
    "    \n",
    "    img_label_path_dict_sel = select_train_val_test(img_label_path_dict, fname_list)\n",
    "    \n",
    "    img_path_arr = np.concatenate([[*img_path_ls] for img_path_ls, _ in img_label_path_dict_sel.values()])\n",
    "    label_path_arr = np.array([[label for _ in range(len(img_path_ls))] for img_path_ls, label in img_label_path_dict_sel.values()])\n",
    "    return img_path_arr, np.hstack(label_path_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dwi_adc_mask_loader(dwi_adc_mask_path):\n",
    "    dwi_path, adc_path, mask_path = dwi_adc_mask_path\n",
    "    dwi_img = np.array(Image.open(dwi_path))\n",
    "    adc_img = np.array(Image.open(adc_path))\n",
    "    mask_img = np.array(Image.open(mask_path))\n",
    "    return np.stack([dwi_img, adc_img, mask_img], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets, models, transforms\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "\n",
    "def get_training_augmentation(params=None):\n",
    "    transform_list = []\n",
    "    \n",
    "    #transform_list.append(A.HorizontalFlip(p=.5))\n",
    "    #transform_list.append(A.VerticalFlip(p=.5))\n",
    "    #transform_list.append(A.ShiftScaleRotate(scale_limit=0.1, rotate_limit=5, shift_limit=0.2, border_mode=0, p=.5))\n",
    "    #transform_list.append(A.ShiftScaleRotate(scale_limit=0.01, rotate_limit=5, shift_limit=0., border_mode=0, p=.5))\n",
    "    \n",
    "    return A.Compose(transform_list)\n",
    "\n",
    "\n",
    "def get_preprocessing(params=None,resize=(256,256),convert=True):\n",
    "    transform_list = []\n",
    "    transform_list.append(A.Resize(*resize))\n",
    "    if convert:\n",
    "        #transform_list.append(A.Normalize(mean=(0.5,0.5),  std=(0.5,0.5)))\n",
    "        transform_list.append(A.Normalize(mean=(0.485, 0.456, 0.406),  std=(0.229, 0.224, 0.225)))\n",
    "        transform_list.append(ToTensorV2(transpose_mask=True))\n",
    "    return A.Compose(transform_list)\n",
    "\n",
    "\n",
    "class AIHUB_DWI_ADC_OutcomePredDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, \n",
    "                 img_folder_dir, \n",
    "                 data_df_path,\n",
    "                 img_loader=dwi_adc_mask_loader, \n",
    "                 augmentation=None, \n",
    "                 preprocessing=None,\n",
    "                 mode='train'\n",
    "    ):\n",
    "        self.data_df = pd.read_csv(data_df_path)\n",
    "        self.img_loader = img_loader\n",
    "        self.augmentation = augmentation\n",
    "        self.preprocessing = preprocessing\n",
    "        self.mode = mode\n",
    "        if self.mode:\n",
    "            self.fname_list = self.data_df[self.data_df[\"fold_3\"] == self.mode].name.values\n",
    "        else:\n",
    "            self.fname_list = self.data_df.name.values\n",
    "        \n",
    "        self.img_path_arr, self.label_arr = find_aihub_img_label_paths(img_folder_dir, self.data_df, self.fname_list)\n",
    "        if self.mode != 'train':\n",
    "            self.augmentation = None\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        image = self.img_loader(self.img_path_arr[index])\n",
    "        label = self.label_arr[index]\n",
    "        if self.augmentation:\n",
    "            sample = self.augmentation(image=image)\n",
    "            image = sample['image']\n",
    "        if self.preprocessing:\n",
    "            sample = self.preprocessing(image=image)\n",
    "            image = sample['image']\n",
    "        \n",
    "        return image, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_path_arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = AIHUB_DWI_ADC_OutcomePredDataset(\n",
    "    img_folder_dir = '/home/ncp/workspace/blocks1/dicom_to_png_2d/', \n",
    "    data_df_path = '/home/ncp/workspace/blocks1/aihub_df_v.KF.csv', \n",
    "    augmentation=None, \n",
    "    preprocessing=get_preprocessing(resize=(256,256)),\n",
    "    mode='train'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_dataset = AIHUB_DWI_ADC_OutcomePredDataset(\n",
    "    img_folder_dir = '/home/ncp/workspace/blocks1/dicom_to_png_2d/', \n",
    "    data_df_path = '/home/ncp/workspace/blocks1/aihub_df_v.KF.csv', \n",
    "    augmentation=None, \n",
    "    preprocessing=get_preprocessing(resize=(256,256), convert=False),\n",
    "    mode='val',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(**images):\n",
    "    \"\"\"PLot images in one row.\"\"\"\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(16, 5))\n",
    "    for i, (name, image) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i + 1)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(' '.join(name.split('_')).title())\n",
    "        plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def normalize(arr):\n",
    "    tmp = (arr - arr.min())/(arr.max()-arr.min())*255\n",
    "    return tmp.astype(np.uint8)\n",
    "\n",
    "\n",
    "def visualize_grayscale(arr):\n",
    "    tmp = normalize(arr)\n",
    "    return np.stack([tmp, tmp, tmp], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check augmentation \n",
    "# for i in range(0,12):\n",
    "#     image, mask = aug_dataset[i] \n",
    "#     visualize(image=visualize_grayscale(np.squeeze(image[:,:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, \n",
    "                 patience=7, \n",
    "                 verbose=False, \n",
    "                 delta=0, \n",
    "                 path='checkpoint.pt', \n",
    "                 trace_func=print):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.counter = 0\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased {self.val_loss_min:.6f} --> {val_loss:.6f}. Saving Model...')\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimizer, epoch, n_epochs, print_freq=100):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    error = AverageMeter()\n",
    "    \n",
    "    model.cuda()\n",
    "    model.train()\n",
    "    \n",
    "    end = time.time()\n",
    "    for batch_idx, (input, target) in enumerate(loader):\n",
    "        if torch.cuda.is_available():\n",
    "            input = input.cuda()\n",
    "            target = target.cuda()\n",
    "        \n",
    "        output = model(input)\n",
    "        loss = torch.nn.functional.cross_entropy(output, target)\n",
    "        \n",
    "        batch_size = target.size(0)\n",
    "        _, pred = output.data.cpu().topk(1, dim=1)\n",
    "        error.update(torch.ne(pred.squeeze(), target.cpu()).float().sum().item() / batch_size, batch_size)\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "        if batch_idx % print_freq == 0:\n",
    "            res = '\\t'.join([\n",
    "                'Epoch: [%d/%d]' % (epoch+1, n_epochs),\n",
    "                'Iter: [%d/%d]' % (batch_idx+1, len(loader)),\n",
    "                'Time %.3f (%.3f)' % (batch_time.val, batch_time.avg),\n",
    "                'Loss %.4f (%.4f)' % (losses.val, losses.avg),\n",
    "                'Error %.4f (%.4f)' % (error.val, error.avg),\n",
    "            ])\n",
    "            print(res)\n",
    "        \n",
    "    return batch_time.avg, losses.avg, error.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch(model, loader, print_freq=5, is_test=True):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    error = AverageMeter()\n",
    "    \n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    \n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (input, target) in enumerate(loader):\n",
    "            if torch.cuda.is_available():\n",
    "                input = input.cuda()\n",
    "                target = target.cuda()\n",
    "        \n",
    "            output = model(input)\n",
    "            loss = torch.nn.functional.cross_entropy(output, target)\n",
    "        \n",
    "            batch_size = target.size(0)\n",
    "            _, pred = output.data.cpu().topk(1, dim=1)\n",
    "            error.update(torch.ne(pred.squeeze(), target.cpu()).float().sum().item() / batch_size, batch_size)\n",
    "            losses.update(loss.item(), batch_size)\n",
    "        \n",
    "            \n",
    "        \n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "        \n",
    "            if batch_idx % print_freq == 0:\n",
    "                res = '\\t'.join([\n",
    "                    'Test:' if is_test else 'Valid',\n",
    "                    'Iter: [%d/%d]' % (batch_idx+1, len(loader)),\n",
    "                    'Time %.3f (%.3f)' % (batch_time.val, batch_time.avg),\n",
    "                    'Loss %.4f (%.4f)' % (losses.val, losses.avg),\n",
    "                    'Error %.4f (%.4f)' % (error.val, error.avg),\n",
    "                ])\n",
    "                print(res)\n",
    "        \n",
    "        return batch_time.avg, losses.avg, error.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_set, valid_set, test_set, save, n_epochs=300,\n",
    "         batch_size=64, lr=0.0001, patience=10, save_epoch=10, seed=None):\n",
    "    cnt=0\n",
    "    if seed is not None:\n",
    "        torch.manual_seed(seed)\n",
    "        \n",
    "    train_loader = torch.utils.data.DataLoader(train_set,\n",
    "                                              batch_size=batch_size, drop_last=True, shuffle=True,\n",
    "                                              pin_memory=(torch.cuda.is_available()), num_workers=0)\n",
    "    test_loader = torch.utils.data.DataLoader(test_set,\n",
    "                                              batch_size=batch_size, shuffle=False,\n",
    "                                              pin_memory=(torch.cuda.is_available()), num_workers=0)\n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
    "    if valid_set is None:\n",
    "        valid_loader = None\n",
    "    else:\n",
    "        valid_loader = torch.utils.data.DataLoader(valid_set,\n",
    "                                                  batch_size=batch_size, shuffle=False,\n",
    "                                                  pin_memory=(torch.cuda.is_available()), num_workers=0)\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "    \n",
    "    model_wrapper = model\n",
    "    if torch.cuda.is_available() and torch.cuda.device_count() > 1:\n",
    "        model_wrapper = torch.nn.DataParallel(model).cuda()\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model_wrapper.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[0.5*n_epochs, 0.75*n_epochs],\n",
    "                                                    gamma = 0.1)\n",
    "    \n",
    "    with open(os.path.join(save, 'results.csv'), 'w') as f:\n",
    "        f.write('epoch,train_loss,train_error,valid_loss,valid_error,test_error\\n')\n",
    "    \n",
    "    best_error = 1\n",
    "    for epoch in range(n_epochs):\n",
    "        _, train_loss, train_error = train_epoch(\n",
    "            model=model_wrapper, \n",
    "            loader=train_loader, \n",
    "            optimizer=optimizer, \n",
    "            epoch=epoch, \n",
    "            n_epochs=n_epochs,\n",
    "        )\n",
    "        scheduler.step()\n",
    "        _, valid_loss, valid_error = test_epoch(\n",
    "            model=model_wrapper, \n",
    "            loader=valid_loader if valid_loader else test_loader, \n",
    "            is_test=(not valid_loader)\n",
    "        )\n",
    "        \n",
    "        if valid_loader:\n",
    "            if valid_error < best_error:\n",
    "                best_error = valid_error\n",
    "                print('New best error: %.4f' % best_error)\n",
    "                torch.save(model.state_dict(), os.path.join(save, 'model_best.dat'))\n",
    "        else:\n",
    "            if (cnt%save_epoch==0):\n",
    "                #torch.save(model.state_dict(), os.path.join(save, 'model_epoch'+str(cnt).zfill(3)+'dat'))\n",
    "                pass\n",
    "        \n",
    "        with open(os.path.join(save, 'results.csv'), 'a') as f:\n",
    "            f.write('%04d,%0.6f,%0.6f,%0.5f,%0.5f,\\n' % (\n",
    "                (epoch+1), \n",
    "                train_loss, \n",
    "                train_error, \n",
    "                valid_loss, \n",
    "                valid_error\n",
    "            ))\n",
    "        cnt += 1\n",
    "        \n",
    "        early_stopping(valid_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print('Early stopping')\n",
    "            break\n",
    "    \n",
    "    torch.save(model.state_dict(), os.path.join(save, 'model_final.dat'))\n",
    "    \n",
    "    model.load_state_dict(torch.load(os.path.join(save, 'model_final.dat')))\n",
    "    if torch.cuda.is_available() and torch.cuda.device_count() > 1:\n",
    "        model = torch.nn.DataParallel(model).cuda()\n",
    "    test_results = test_epoch(\n",
    "        model=model, \n",
    "        loader=test_loader, \n",
    "        is_test=True\n",
    "    )\n",
    "    \n",
    "    _, _, test_error = test_results\n",
    "    with open(os.path.join(save, 'results.csv'), 'a') as f:\n",
    "        f.write(',,,,,%0.5f\\n' % (test_error))\n",
    "    print('Final test error: %.4f' % test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo(save, \n",
    "         model, \n",
    "         n_epochs=300, \n",
    "         batch_size=64, \n",
    "         lr=0.0001, \n",
    "         patience=10, \n",
    "         seed=None):\n",
    "    train_dataset = AIHUB_DWI_ADC_OutcomePredDataset(\n",
    "        img_folder_dir = '/home/ncp/workspace/blocks1/dicom_to_png_2d/', \n",
    "        data_df_path = '/home/ncp/workspace/blocks1/aihub_df_v.KF.csv', \n",
    "        augmentation=None, \n",
    "        preprocessing=get_preprocessing(resize=(256,256)),\n",
    "        mode='train'\n",
    "        )\n",
    "    val_dataset = AIHUB_DWI_ADC_OutcomePredDataset(\n",
    "        img_folder_dir = '/home/ncp/workspace/blocks1/dicom_to_png_2d/', \n",
    "        data_df_path = '/home/ncp/workspace/blocks1/aihub_df_v.KF.csv', \n",
    "        augmentation=None, \n",
    "        preprocessing=get_preprocessing(resize=(256,256)),\n",
    "        mode='val'\n",
    "        )\n",
    "    test_dataset = AIHUB_DWI_ADC_OutcomePredDataset(\n",
    "        img_folder_dir = '/home/ncp/workspace/blocks1/dicom_to_png_2d/', \n",
    "        data_df_path = '/home/ncp/workspace/blocks1/aihub_df_v.KF.csv', \n",
    "        augmentation=None, \n",
    "        preprocessing=get_preprocessing(resize=(256,256)),\n",
    "        mode='test'\n",
    "        )\n",
    "    \n",
    "    num_params = sum(p.numel() for p in model.parameters())\n",
    "    print('Total parameters: ', num_params)\n",
    "    \n",
    "    if not os.path.exists(save):\n",
    "        os.makedirs(save)\n",
    "    if not os.path.isdir(save):\n",
    "        raise Exception('%s is not a dir' % save)\n",
    "    \n",
    "    train(model=model, train_set=train_dataset, valid_set=val_dataset, test_set=test_dataset, save=save, n_epochs=n_epochs,\n",
    "         batch_size=batch_size, lr=lr, patience=patience, seed=seed)\n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = './2D/DWIADCMASKPred/2DDensenet169'\n",
    "gen_new_dir(save_path)\n",
    "N_EPOCHS = 10000\n",
    "BATCH_SIZE = 8\n",
    "LR = 0.0001\n",
    "PATIENCE = 10\n",
    "\n",
    "model = timm.create_model('densenet169',pretrained=True)\n",
    "model.classifier = torch.nn.Sequential(\n",
    "    torch.nn.Linear(in_features=1664, out_features=2, bias=True),\n",
    "    torch.nn.Softmax(dim=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo(save=save_path, \n",
    "     model=model, \n",
    "     n_epochs=N_EPOCHS, \n",
    "     batch_size=BATCH_SIZE, \n",
    "     lr=LR, \n",
    "     patience=PATIENCE, \n",
    "     seed=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = './2D/DWIADCMASKPred/2DDensenet169'\n",
    "test_model = timm.create_model('densenet169',pretrained=True)\n",
    "test_model.classifier = torch.nn.Sequential(\n",
    "    torch.nn.Linear(in_features=1664, out_features=2, bias=True),\n",
    "    torch.nn.Softmax(dim=1)\n",
    ")\n",
    "test_model.load_state_dict(torch.load(os.path.join(save_path, 'model_best.dat')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = AIHUB_DWI_ADC_OutcomePredDataset(\n",
    "        img_folder_dir = '/home/ncp/workspace/blocks1/dicom_to_png_2d/', \n",
    "        data_df_path = '/home/ncp/workspace/blocks1/aihub_df_v.KF.csv', \n",
    "        augmentation=None, \n",
    "        preprocessing=get_preprocessing(resize=(256,256)),\n",
    "        mode='train'\n",
    "        )\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_out_proba = []\n",
    "test_model.cuda()\n",
    "test_model.eval()\n",
    "\n",
    "for data in tqdm(train_loader):\n",
    "    images, labels = data\n",
    "    images = images.cuda()\n",
    "    masks = labels.cuda()\n",
    "    pr_mask = test_model(images)\n",
    "    train_out_proba.append(pr_mask.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_info_df = pd.read_csv('/home/ncp/workspace/blocks1/aihub_df_v.KF.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df = pd.read_csv('/home/ncp/workspace/blocks1/2d_slice_encoded_value_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_out_proba = np.vstack(train_out_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "train_pred = []\n",
    "train_name_and_label_ls = []\n",
    "name_label_arr = data_info_df[data_info_df.fold_3 == 'train'][['name','bad_outcome_3m']].values\n",
    "for name, label in name_label_arr:\n",
    "    if len(dataset_df[(dataset_df.name==name)]) > 0:\n",
    "        selected_slice = dataset_df[(dataset_df.name==name)]\n",
    "        selected_slice_num = len(selected_slice)\n",
    "        #sol = np.sum(test_out_proba[i:i+selected_slice_num][:,1])/selected_slice_num\n",
    "        sol = np.mean(train_out_proba[i:i+selected_slice_num][:,1])\n",
    "        #sol_std = np.std(test_out_proba[i:i+selected_slice_num][:,1])\n",
    "        #sol = np.max(test_out_proba[i:i+selected_slice_num][:,1])\n",
    "        i += selected_slice_num\n",
    "        train_name_and_label_ls.append([name, label])\n",
    "        train_pred.append(sol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = np.array(train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_df = pd.read_csv('/home/ncp/workspace/AIHUB_dataset/df_csv_merged_v2.1.1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lesion_area_df = pd.read_csv('/home/ncp/workspace/blocks2/pred_lesion_area_df_og.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_info_arr = []\n",
    "lesion_info_arr = []\n",
    "label_arr = []\n",
    "for fname, label in train_name_and_label_ls:\n",
    "    tabular_info = tabular_df[tabular_df.name == fname][['pre_good_mrs', 'age_cate', 'ini_nih', 'END']].values\n",
    "    lesion_area_info = pred_lesion_area_df[pred_lesion_area_df.name == fname].pred_lesion_area.values[0] #*100000\n",
    "    tabular_info_arr.append(tabular_info)\n",
    "    lesion_info_arr.append(lesion_area_info)\n",
    "    label_arr.append(label)\n",
    "tabular_info_arr = np.array(tabular_info_arr)\n",
    "lesion_info_arr = np.array(lesion_info_arr)\n",
    "label_arr = np.array(label_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.hstack([np.squeeze(tabular_info_arr), train_pred[:,np.newaxis], lesion_info_arr[:,np.newaxis]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = label_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XY_train_df = pd.DataFrame(np.hstack([X_train, Y_train[:,np.newaxis]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XY_train_df.dropna(axis=0, inplace=True, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=500, max_depth=5, random_state=17)\n",
    "model.fit(XY_train_df.iloc[:,:6], XY_train_df.iloc[:,6])#XY_train_df.iloc[:,:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(save_path, 'ensemble3.pkl'), 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = AIHUB_DWI_ADC_OutcomePredDataset(\n",
    "        img_folder_dir = '/home/ncp/workspace/blocks1/dicom_to_png_2d/', \n",
    "        data_df_path = '/home/ncp/workspace/blocks1/aihub_df_v.KF.csv', \n",
    "        augmentation=None, \n",
    "        preprocessing=get_preprocessing(resize=(256,256)),\n",
    "        mode='val'\n",
    "        )\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_out_proba = []\n",
    "test_model.cuda()\n",
    "test_model.eval()\n",
    "\n",
    "for data in tqdm(val_loader):\n",
    "    images, labels = data\n",
    "    images = images.cuda()\n",
    "    masks = labels.cuda()\n",
    "    pr_mask = test_model(images)\n",
    "    val_out_proba.append(pr_mask.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_out_proba = np.vstack(val_out_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "val_pred = []\n",
    "val_name_and_label_ls = []\n",
    "name_label_arr = data_info_df[data_info_df.fold_3 == 'val'][['name','bad_outcome_3m']].values\n",
    "for name, label in name_label_arr:\n",
    "    if len(dataset_df[(dataset_df.name==name)]) > 0:\n",
    "        selected_slice = dataset_df[(dataset_df.name==name)]\n",
    "        selected_slice_num = len(selected_slice)\n",
    "        #sol = np.sum(test_out_proba[i:i+selected_slice_num][:,1])/selected_slice_num\n",
    "        sol = np.mean(val_out_proba[i:i+selected_slice_num][:,1])\n",
    "        #sol_std = np.std(test_out_proba[i:i+selected_slice_num][:,1])\n",
    "        #sol = np.max(test_out_proba[i:i+selected_slice_num][:,1])\n",
    "        i += selected_slice_num\n",
    "        val_name_and_label_ls.append([name, label])\n",
    "        val_pred.append(sol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred = np.array(val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_info_arr = []\n",
    "lesion_info_arr = []\n",
    "label_arr = []\n",
    "for fname, label in val_name_and_label_ls:\n",
    "    tabular_info = tabular_df[tabular_df.name == fname][['pre_good_mrs', 'age_cate', 'ini_nih', 'END']].values\n",
    "    lesion_area_info = pred_lesion_area_df[pred_lesion_area_df.name == fname].pred_lesion_area.values[0] #*100000\n",
    "    tabular_info_arr.append(tabular_info)\n",
    "    lesion_info_arr.append(lesion_area_info)\n",
    "    label_arr.append(label)\n",
    "tabular_info_arr = np.array(tabular_info_arr)\n",
    "lesion_info_arr = np.array(lesion_info_arr)\n",
    "label_arr = np.array(label_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = np.hstack([np.squeeze(tabular_info_arr), val_pred[:,np.newaxis], lesion_info_arr[:,np.newaxis]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_val = label_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XY_val_df = pd.DataFrame(np.hstack([X_val, Y_val[:,np.newaxis]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XY_val_df.dropna(axis=0, inplace=True, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cldlvol_val_out_proba = model.predict_proba(XY_val_df.iloc[:,:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_label = XY_val_df.iloc[:,6].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(Y_label==1, cldlvol_val_out_proba[:,1])\n",
    "J = tpr - fpr # Youden's J statistic\n",
    "idx = np.argmax(J)\n",
    "best_thresh = thresholds[idx]\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "sens, spec = tpr[idx], 1-fpr[idx]\n",
    "print(f\"ROCAUC:\\t\\t\\t\\t\\t{roc_auc}\")\n",
    "print(f\"Best threshold(Youden's J statistic):\\t{best_thresh}\")\n",
    "print(f\"Sensitivity:\\t\\t\\t\\t{sens}\")\n",
    "print(f\"Specificity:\\t\\t\\t\\t{spec}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(Y_label==1, val_pred)\n",
    "J = tpr - fpr # Youden's J statistic\n",
    "idx = np.argmax(J)\n",
    "best_thresh = thresholds[idx]\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "sens, spec = tpr[idx], 1-fpr[idx]\n",
    "print(f\"ROCAUC:\\t\\t\\t\\t\\t{roc_auc}\")\n",
    "print(f\"Best threshold(Youden's J statistic):\\t{best_thresh}\")\n",
    "print(f\"Sensitivity:\\t\\t\\t\\t{sens}\")\n",
    "print(f\"Specificity:\\t\\t\\t\\t{spec}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = AIHUB_DWI_ADC_OutcomePredDataset(\n",
    "        img_folder_dir = '/home/ncp/workspace/blocks1/dicom_to_png_2d/', \n",
    "        data_df_path = '/home/ncp/workspace/blocks1/aihub_df_v.KF.csv', \n",
    "        augmentation=None, \n",
    "        preprocessing=get_preprocessing(resize=(256,256)),\n",
    "        mode='test'\n",
    "        )\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_out_proba = []\n",
    "test_model.cuda()\n",
    "test_model.eval()\n",
    "\n",
    "for data in tqdm(test_loader):\n",
    "    images, labels = data\n",
    "    images = images.cuda()\n",
    "    masks = labels.cuda()\n",
    "    pr_mask = test_model(images)\n",
    "    test_out_proba.append(pr_mask.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_info_df = pd.read_csv('/home/ncp/workspace/blocks1/aihub_df_v.KF.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df = pd.read_csv('/home/ncp/workspace/blocks1/2d_slice_encoded_value_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_out_proba = np.vstack(test_out_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "test_pred = []\n",
    "test_name_and_label_ls = []\n",
    "name_label_arr = data_info_df[data_info_df.fold_3 == 'test'][['name','bad_outcome_3m']].values\n",
    "for name, label in name_label_arr:\n",
    "    if len(dataset_df[(dataset_df.name==name)]) > 0:\n",
    "        selected_slice = dataset_df[(dataset_df.name==name)]\n",
    "        selected_slice_num = len(selected_slice)\n",
    "        #sol = np.sum(test_out_proba[i:i+selected_slice_num][:,1])/selected_slice_num\n",
    "        sol = np.mean(test_out_proba[i:i+selected_slice_num][:,1])\n",
    "        #sol_std = np.std(test_out_proba[i:i+selected_slice_num][:,1])\n",
    "        #sol = np.max(test_out_proba[i:i+selected_slice_num][:,1])\n",
    "        i += selected_slice_num\n",
    "        test_name_and_label_ls.append([name, label])\n",
    "        test_pred.append(sol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = np.array(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_df = pd.read_csv('/home/ncp/workspace/AIHUB_dataset/df_csv_merged_v2.1.1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lesion_area_df = pd.read_csv('/home/ncp/workspace/blocks2/pred_lesion_area_df_og.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_info_arr = []\n",
    "lesion_info_arr = []\n",
    "label_arr = []\n",
    "for fname, label in test_name_and_label_ls:\n",
    "    tabular_info = tabular_df[tabular_df.name == fname][['pre_good_mrs', 'age_cate', 'ini_nih', 'END']].values\n",
    "    lesion_area_info = pred_lesion_area_df[pred_lesion_area_df.name == fname].pred_lesion_area.values[0] #*100000\n",
    "    tabular_info_arr.append(tabular_info)\n",
    "    lesion_info_arr.append(lesion_area_info)\n",
    "    label_arr.append(label)\n",
    "tabular_info_arr = np.array(tabular_info_arr)\n",
    "lesion_info_arr = np.array(lesion_info_arr)\n",
    "label_arr = np.array(label_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.hstack([np.squeeze(tabular_info_arr), test_pred[:,np.newaxis], lesion_info_arr[:,np.newaxis]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = label_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XY_test_df = pd.DataFrame(np.hstack([X_test, Y_test[:,np.newaxis]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XY_test_df.dropna(axis=0, inplace=True, how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cldlvol_test_out_proba = model.predict_proba(XY_test_df.iloc[:,:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_label = XY_test_df.iloc[:,6].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(Y_label==1, cldlvol_test_out_proba[:,1])\n",
    "J = tpr - fpr # Youden's J statistic\n",
    "idx = np.argmax(J)\n",
    "best_thresh = thresholds[idx]\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "sens, spec = tpr[idx], 1-fpr[idx]\n",
    "print(f\"ROCAUC:\\t\\t\\t\\t\\t{roc_auc}\")\n",
    "print(f\"Best threshold(Youden's J statistic):\\t{best_thresh}\")\n",
    "print(f\"Sensitivity:\\t\\t\\t\\t{sens}\")\n",
    "print(f\"Specificity:\\t\\t\\t\\t{spec}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(Y_test==1, test_pred)\n",
    "J = tpr - fpr # Youden's J statistic\n",
    "idx = np.argmax(J)\n",
    "best_thresh = thresholds[idx]\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "sens, spec = tpr[idx], 1-fpr[idx]\n",
    "print(f\"ROCAUC:\\t\\t\\t\\t\\t{roc_auc}\")\n",
    "print(f\"Best threshold(Youden's J statistic):\\t{best_thresh}\")\n",
    "print(f\"Sensitivity:\\t\\t\\t\\t{sens}\")\n",
    "print(f\"Specificity:\\t\\t\\t\\t{spec}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cd = RandomForestClassifier(n_estimators=500,max_depth=5, random_state=17)\n",
    "model_cd.fit(XY_train_df.iloc[:,:4], XY_train_df.iloc[:,6])#XY_train_df.iloc[:,:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_val_out_proba = model_cd.predict_proba(XY_val_df.iloc[:,:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(XY_val_df.iloc[:,6].values==1, cl_val_out_proba[:,1])\n",
    "J = tpr - fpr # Youden's J statistic\n",
    "idx = np.argmax(J)\n",
    "best_thresh = thresholds[idx]\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "sens, spec = tpr[idx], 1-fpr[idx]\n",
    "print(f\"ROCAUC:\\t\\t\\t\\t\\t{roc_auc}\")\n",
    "print(f\"Best threshold(Youden's J statistic):\\t{best_thresh}\")\n",
    "print(f\"Sensitivity:\\t\\t\\t\\t{sens}\")\n",
    "print(f\"Specificity:\\t\\t\\t\\t{spec}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_test_out_proba = model_cd.predict_proba(XY_test_df.iloc[:,:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(XY_test_df.iloc[:,6].values==1, cl_test_out_proba[:,1])\n",
    "J = tpr - fpr # Youden's J statistic\n",
    "idx = np.argmax(J)\n",
    "best_thresh = thresholds[idx]\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "sens, spec = tpr[idx], 1-fpr[idx]\n",
    "print(f\"ROCAUC:\\t\\t\\t\\t\\t{roc_auc}\")\n",
    "print(f\"Best threshold(Youden's J statistic):\\t{best_thresh}\")\n",
    "print(f\"Sensitivity:\\t\\t\\t\\t{sens}\")\n",
    "print(f\"Specificity:\\t\\t\\t\\t{spec}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(save_path, 'clinical_data.pkl'), 'wb') as f:\n",
    "    pickle.dump(model_cd, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cd = RandomForestClassifier(n_estimators=500,max_depth=5, random_state=17)\n",
    "model_cd.fit(XY_train_df.iloc[:,:5], XY_train_df.iloc[:,6])#XY_train_df.iloc[:,:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cldl_val_out_proba = model_cd.predict_proba(XY_val_df.iloc[:,:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(XY_val_df.iloc[:,6].values==1, cldl_val_out_proba[:,1])\n",
    "J = tpr - fpr # Youden's J statistic\n",
    "idx = np.argmax(J)\n",
    "best_thresh = thresholds[idx]\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "sens, spec = tpr[idx], 1-fpr[idx]\n",
    "print(f\"ROCAUC:\\t\\t\\t\\t\\t{roc_auc}\")\n",
    "print(f\"Best threshold(Youden's J statistic):\\t{best_thresh}\")\n",
    "print(f\"Sensitivity:\\t\\t\\t\\t{sens}\")\n",
    "print(f\"Specificity:\\t\\t\\t\\t{spec}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cldl_test_out_proba = model_cd.predict_proba(XY_test_df.iloc[:,:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(XY_test_df.iloc[:,6].values==1, cldl_test_out_proba[:,1])\n",
    "J = tpr - fpr # Youden's J statistic\n",
    "idx = np.argmax(J)\n",
    "best_thresh = thresholds[idx]\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "sens, spec = tpr[idx], 1-fpr[idx]\n",
    "print(f\"ROCAUC:\\t\\t\\t\\t\\t{roc_auc}\")\n",
    "print(f\"Best threshold(Youden's J statistic):\\t{best_thresh}\")\n",
    "print(f\"Sensitivity:\\t\\t\\t\\t{sens}\")\n",
    "print(f\"Specificity:\\t\\t\\t\\t{spec}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(save_path, 'ensemble1.pkl'), 'wb') as f:\n",
    "    pickle.dump(model_cd, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cd = RandomForestClassifier(n_estimators=500,max_depth=5, random_state=17)\n",
    "model_cd.fit(XY_train_df[[0,1,2,3,5]], XY_train_df.iloc[:,6])#XY_train_df.iloc[:,:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_vol_val_out_proba = model_cd.predict_proba(XY_val_df[[0,1,2,3,5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(XY_val_df.iloc[:,6].values==1, cl_vol_val_out_proba[:,1])\n",
    "J = tpr - fpr # Youden's J statistic\n",
    "idx = np.argmax(J)\n",
    "best_thresh = thresholds[idx]\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "sens, spec = tpr[idx], 1-fpr[idx]\n",
    "print(f\"ROCAUC:\\t\\t\\t\\t\\t{roc_auc}\")\n",
    "print(f\"Best threshold(Youden's J statistic):\\t{best_thresh}\")\n",
    "print(f\"Sensitivity:\\t\\t\\t\\t{sens}\")\n",
    "print(f\"Specificity:\\t\\t\\t\\t{spec}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_vol_test_out_proba = model_cd.predict_proba(XY_test_df[[0,1,2,3,5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(XY_test_df.iloc[:,6].values==1, cl_vol_test_out_proba[:,1])\n",
    "J = tpr - fpr # Youden's J statistic\n",
    "idx = np.argmax(J)\n",
    "best_thresh = thresholds[idx]\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "sens, spec = tpr[idx], 1-fpr[idx]\n",
    "print(f\"ROCAUC:\\t\\t\\t\\t\\t{roc_auc}\")\n",
    "print(f\"Best threshold(Youden's J statistic):\\t{best_thresh}\")\n",
    "print(f\"Sensitivity:\\t\\t\\t\\t{sens}\")\n",
    "print(f\"Specificity:\\t\\t\\t\\t{spec}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(save_path, 'ensemble2.pkl'), 'wb') as f:\n",
    "    pickle.dump(model_cd, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_f_path = np.array(val_name_and_label_ls)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_prob = np.stack([val_f_path, \n",
    "                     cl_val_out_proba[:,1], \n",
    "                     val_pred, \n",
    "                     cldl_val_out_proba[:,1], \n",
    "                     cl_vol_val_out_proba[:,1], \n",
    "                     cldlvol_val_out_proba[:,1], \n",
    "                     XY_val_df.iloc[:,6].values], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_prob_df = pd.DataFrame(val_prob, \n",
    "                           columns=['name', \n",
    "                                    'clinical_data', \n",
    "                                    'image_DL', \n",
    "                                    'ensemble1', \n",
    "                                    'ensemble2', \n",
    "                                    'ensemble3', \n",
    "                                    'bad_outcome_3m'])\n",
    "val_prob_df.to_csv(os.path.join(save_path, 'val_prob.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_f_path = np.array(test_name_and_label_ls)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prob = np.stack([test_f_path, \n",
    "                     cl_test_out_proba[:,1], \n",
    "                     test_pred, \n",
    "                     cldl_test_out_proba[:,1], \n",
    "                     cl_vol_test_out_proba[:,1], \n",
    "                     cldlvol_test_out_proba[:,1], \n",
    "                     XY_test_df.iloc[:,6].values], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prob_df = pd.DataFrame(test_prob, \n",
    "                           columns=['name', \n",
    "                                    'clinical_data', \n",
    "                                    'image_DL', \n",
    "                                    'ensemble1', \n",
    "                                    'ensemble2', \n",
    "                                    'ensemble3', \n",
    "                                    'bad_outcome_3m'])\n",
    "test_prob_df.to_csv(os.path.join(save_path, 'test_prob.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
